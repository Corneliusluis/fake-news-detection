{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64596a76-df44-4f7c-95ea-9cc9937875c0",
   "metadata": {},
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177a3c8-e45f-4bc2-aa40-5e9369463b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STILL NEED TO ADD VERSIONS (AFTER FILE IS CONFIRMED)\n",
    "\"\"\"\n",
    "%pip install spacy\n",
    "%pip install pyarrow\n",
    "%pip install textblob\n",
    "%pip install textstat\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba966e-68f2-4df7-a3ef-8f25fbdbe8e1",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbff736-39f8-4787-8ca3-83805762217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS environment\n",
    "import os\n",
    "\n",
    "# Import SparkConf class into program\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# Import SparkContext and SparkSession classes\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# PySpark Data Operations\n",
    "from pyspark.sql.functions import col, size, split, udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Numeric operations\n",
    "import numpy as np\n",
    "\n",
    "# Define custom schema (data types) for PySpark Dataframes\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "# spaCy model for natural language processing\n",
    "import spacy\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Pscholinguistics\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Readability features\n",
    "import textstat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc305d0a",
   "metadata": {},
   "source": [
    "## 3. Function and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1061797-a760-41a2-95bc-0629ff082849",
   "metadata": {},
   "source": [
    "### 3.1. clean_text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c741c78a-9fb0-4769-bed5-2eed16d8326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Clean the input text string by removing unwanted elements while keeping useful punctuation.\n",
    "\n",
    "    Steps performed:\n",
    "    - Convert non-ASCII quotes/aprostrophes with ASCII equivalents\n",
    "    - Remove URLs (e.g. http://..., www...)\n",
    "    - Remove Twitter-style mentions (@username) and hashtags (#hashtag)\n",
    "    - Remove HTML entities (e.g. &nbsp;)\n",
    "    - Remove emojis and non-ASCII characters\n",
    "    - Normalize whitespace (convert multiple spaces/tabs/newlines into a single space)\n",
    "    - Trim leading and trailing spaces\n",
    "\n",
    "    Args:\n",
    "        text (str or None): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: A cleaned version of the input text. If input is None, returns an empty string.\n",
    "    \"\"\"\n",
    "    \n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Replace curly quotes/apostrophes with ASCII equivalents\n",
    "    replacements = {\n",
    "        '“': '\"', '”': '\"',\n",
    "        '‘': \"'\", '’': \"'\"\n",
    "    }\n",
    "    for curly, straight in replacements.items():\n",
    "        text = text.replace(curly, straight)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove HTMLs\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    \n",
    "    # Remove emojis and other non-ASCII symbols\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38dd96-b7e2-4ecb-b69d-771aee837bc8",
   "metadata": {},
   "source": [
    "### 3.2. FeaturesSpark Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb37c0c7-0767-435d-b25e-57e2dc3852a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesSpark:\n",
    "    \"\"\"\n",
    "    Features that can be computed efficiently using PySpark.\n",
    "    \"\"\"\n",
    "    VOWELS = \"aeiouyAEIOUY\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, df, text_col):\n",
    "        txt = F.coalesce(F.col(text_col), F.lit(\"\"))\n",
    "\n",
    "        # Character count\n",
    "        df = df.withColumn(\"num_characters\", F.length(txt))\n",
    "\n",
    "        # Capital letters\n",
    "        df = df.withColumn(\"num_capital_letters\", F.length(F.regexp_replace(txt, r\"[^A-Z]\", \"\")))\n",
    "\n",
    "        # Word count\n",
    "        df = df.withColumn(\"num_words\", F.size(F.split(txt, r\"\\s+\")))\n",
    "\n",
    "        # Sentence count\n",
    "        df = df.withColumn(\"num_sentences\", F.size(F.split(txt, r\"[.!?]+\")))\n",
    "\n",
    "        # Words per sentence\n",
    "        df = df.withColumn(\n",
    "            \"words_per_sentence\", \n",
    "            F.when(F.col(\"num_sentences\") > 0, F.col(\"num_words\") / F.col(\"num_sentences\"))\n",
    "             .otherwise(F.lit(0))\n",
    "        )\n",
    "\n",
    "        # Short sentences (<10 words)\n",
    "        df = df.withColumn(\n",
    "            \"num_short_sentences\", \n",
    "            F.size(F.expr(f\"filter(split({text_col}, '[.!?]+'), x -> size(split(x, ' ')) < 10)\"))\n",
    "        )\n",
    "\n",
    "        # Long sentences (>=20 words)\n",
    "        df = df.withColumn(\n",
    "            \"num_long_sentences\", \n",
    "            F.size(F.expr(f\"filter(split({text_col}, '[.!?]+'), x -> size(split(x, ' ')) >= 20)\"))\n",
    "        )\n",
    "\n",
    "        # Special characters\n",
    "        df = df.withColumn(\"num_special_characters\", F.length(F.regexp_replace(txt, r\"[a-zA-Z0-9\\s]\", \"\")))\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f1654-e1f3-449b-b2d2-422187f02d76",
   "metadata": {},
   "source": [
    "### 3.3. POSFeatures Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8404993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSFeatures:\n",
    "    def __init__(self, model=\"en_core_web_sm\"):\n",
    "        self.model = model\n",
    "\n",
    "    def _count_pos(self, text, pos_tag):\n",
    "        # load model lazily (cached per worker)\n",
    "        if not hasattr(self, \"_nlp\"):\n",
    "            self._nlp = spacy.load(self.model, disable=[\"ner\", \"parser\"])\n",
    "        doc = self._nlp(text)\n",
    "        return sum(1 for token in doc if token.pos_ == pos_tag)\n",
    "\n",
    "    def register_udfs(self, spark):\n",
    "        return {\n",
    "            \"num_nouns\": udf(lambda text: self._count_pos(text, \"NOUN\"), IntegerType()),\n",
    "            \"num_verbs\": udf(lambda text: self._count_pos(text, \"VERB\"), IntegerType()),\n",
    "            \"num_adjectives\": udf(lambda text: self._count_pos(text, \"ADJ\"), IntegerType()),\n",
    "            \"num_adverbs\": udf(lambda text: self._count_pos(text, \"ADV\"), IntegerType()),\n",
    "            \"num_determiners\": udf(lambda text: self._count_pos(text, \"DET\"), IntegerType()),\n",
    "        }\n",
    "\n",
    "    def transform(self, df, text_col):\n",
    "        spark = df.sql_ctx.sparkSession\n",
    "        udfs = self.register_udfs(spark)\n",
    "        for col_name, func in udfs.items():\n",
    "            df = df.withColumn(col_name, func(text_col))\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8abbf-5084-44e6-9c55-96ca0983dc65",
   "metadata": {},
   "source": [
    "### 3.4. ReadabilityIndices Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebaec79-5f76-4a8b-9a21-b0b735884e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadabilityIndices:\n",
    "    @staticmethod\n",
    "    def extract_features(df, text_col):\n",
    "        # Regular UDFs\n",
    "        gf_udf = F.udf(lambda t: float(textstat.gunning_fog(t)) if t else None, FloatType())\n",
    "        smog_udf = F.udf(lambda t: float(textstat.smog_index(t)) if t else None, FloatType())\n",
    "        ari_udf = F.udf(lambda t: float(textstat.automated_readability_index(t)) if t else None, FloatType())\n",
    "        syllables_udf = F.udf(lambda t: float(textstat.syllable_count(t)) if t else None, FloatType())\n",
    "\n",
    "        return (df\n",
    "            .withColumn(\"gunning_fog\", gf_udf(F.col(text_col)))\n",
    "            .withColumn(\"smog\", smog_udf(F.col(text_col)))\n",
    "            .withColumn(\"ari\", ari_udf(F.col(text_col)))\n",
    "            .withColumn(\"num_syllables\", syllables_udf(F.col(text_col)))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85448a4-32a2-422e-8fe2-164bac076764",
   "metadata": {},
   "source": [
    "### 3.5. Psycholinguistics Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d9bf4e5-4f71-4295-88a4-d15d78af9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Psycholinguistics:\n",
    "    @staticmethod\n",
    "    def extract_features(df, text_col, title_col=None):\n",
    "        # polarity\n",
    "        def polarity_udf(text):\n",
    "            if not text:\n",
    "                return None\n",
    "            return float(TextBlob(text).sentiment.polarity)\n",
    "        \n",
    "        # subjectivity\n",
    "        def subjectivity_udf(text):\n",
    "            if not text:\n",
    "                return None\n",
    "            return float(TextBlob(text).sentiment.subjectivity)\n",
    "        \n",
    "        # title similarity\n",
    "        def title_similarity_udf(text, title):\n",
    "            if not text or not title:\n",
    "                return None\n",
    "            text_words = set(text.lower().split())\n",
    "            title_words = set(title.lower().split())\n",
    "            if not text_words or not title_words:\n",
    "                return 0\n",
    "            return float(len(text_words & title_words) / len(text_words | title_words))\n",
    "\n",
    "        df = df.withColumn(\"polarity\", F.udf(polarity_udf, FloatType())(F.col(text_col)))\n",
    "        df = df.withColumn(\"subjectivity\", F.udf(subjectivity_udf, FloatType())(F.col(text_col)))\n",
    "        if title_col:\n",
    "            df = df.withColumn(\"title_similarity\", F.udf(title_similarity_udf, FloatType())(\n",
    "                F.col(text_col), F.col(title_col)\n",
    "            ))\n",
    "        else:\n",
    "            df = df.withColumn(\"title_similarity\", F.lit(None).cast(FloatType()))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35e8fa",
   "metadata": {},
   "source": [
    "## 4. Configure Spark Environment\n",
    "Using the code snippets from tutorial 1 and 2, set up the Spark environment and configure the Spark Application using SparkConf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcde57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_home = os.environ.get(\"SPARK_HOME\")\n",
    "\n",
    "# if spark_home:\n",
    "#     print(f\"SPARK_HOME: {spark_home}\")\n",
    "# else:\n",
    "#     print(\"SPARK_HOME environement variable is not set.\")\n",
    "\n",
    "# os.environ[\"SPARK_HOME\"]= \"/usr/local/lib/python3.10/dist-packages/pyspark\"\n",
    "\n",
    "# print (f\"SPARK_HOME is now set to: {os.environ.get('SPARK_HOME')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e920c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local[*]: run Spark in local mode with as many working processors as logical cores on your machine\n",
    "# # If we want Spark to run locally with 'k' worker threads, we can specify as \"local[k]\".\n",
    "# master = \"local[*]\"\n",
    "# # The `appName` field is a name to be shown on the Spark cluster UI page\n",
    "# app_name = \"WELFake Exploratory Data Anlaysis (EDA)\"\n",
    "# # Setup configuration parameters for Spark\n",
    "# spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "\n",
    "# # Setup SparkSession\n",
    "# spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7792048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/19 22:25:55 WARN Utils: Your hostname, nel-X600-ITX resolves to a loopback address: 127.0.1.1; using 192.168.0.23 instead (on interface wlp4s0)\n",
      "25/08/19 22:25:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/nel/iti5202_big_data/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "25/08/19 22:25:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/19 22:25:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/08/19 22:25:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session started with settings:\n",
      "spark.memory.offHeap.size = 4g\n",
      "spark.driver.memory = 32g\n",
      "spark.memory.fraction = 0.8\n",
      "spark.memory.offHeap.enabled = true\n",
      "spark.executor.memory = 32g\n",
      "spark.executor.cores = 8\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[12]\")               # safer: 8 threads instead of 16\n",
    "    .setAppName(\"Fake News Detection\")\n",
    "    .set(\"spark.driver.memory\", \"32g\")\n",
    "    .set(\"spark.executor.memory\", \"32g\")\n",
    "    .set(\"spark.executor.cores\", \"8\")\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"256\")\n",
    "    .set(\"spark.memory.fraction\", \"0.8\")\n",
    "    .set(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .set(\"spark.memory.offHeap.size\", \"4g\")\n",
    ")\n",
    "\n",
    "# Setup SparkSession\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark Session started with settings:\")\n",
    "for k, v in sc.getConf().getAll():\n",
    "    if \"memory\" in k or \"cores\" in k:\n",
    "        print(f\"{k} = {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b156532",
   "metadata": {},
   "source": [
    "## 5. Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838b6a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-----+\n",
      "|_c0|               title|                text|label|\n",
      "+---+--------------------+--------------------+-----+\n",
      "|  0|LAW ENFORCEMENT O...|No comment is exp...|    1|\n",
      "|  1|                null|Did they post the...|    1|\n",
      "|  2|UNBELIEVABLE! OBA...| Now, most of the...|    1|\n",
      "+---+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset into Spark dataframe\n",
    "welfake_df = spark.read.csv(\n",
    "    \"WELFake_Dataset.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    quote='\"', \n",
    "    multiLine=True, #multilines in text and title data\n",
    "    escape='\"'\n",
    ")\n",
    "\n",
    "# Display sample rows\n",
    "welfake_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27f1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 72134\n",
      "Columns: 4\n",
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Rename first column as index\n",
    "welfake_df = welfake_df.withColumnRenamed(\"_c0\", \"index\")\n",
    "\n",
    "# Show dataframe dimensions\n",
    "num_rows = welfake_df.count()\n",
    "num_cols = len(welfake_df.columns)\n",
    "\n",
    "print(f\"Rows: {num_rows}\")\n",
    "print(f\"Columns: {num_cols}\")\n",
    "\n",
    "#Print the Schema\n",
    "welfake_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f772423",
   "metadata": {},
   "source": [
    "## 6. Remove duplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda89b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 72134\n",
      "Duplicates removed: 8456\n",
      "After dataset size: 63678 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count original dataset rows\n",
    "original_count = welfake_df.count()\n",
    "\n",
    "# Remove duplicate news articles\n",
    "welfake_df_dedup = welfake_df.dropDuplicates([\"title\", \"text\"])\n",
    "\n",
    "deduped_count = welfake_df_dedup.count()\n",
    "duplicates_removed = original_count - deduped_count\n",
    "\n",
    "print(f\"Original rows: {original_count}\")\n",
    "print(f\"Duplicates removed: {duplicates_removed}\")\n",
    "print(f\"After dataset size: {deduped_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52a567",
   "metadata": {},
   "source": [
    "## 7. Clean title and article texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7258a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register udf to pyspark\n",
    "clean_text_udf = udf(clean_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                                           title|                                                                   cleaned_title|                                                                            text|                                                                    cleaned_text|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                         Wingsuit flyer vs. tree|                                                         Wingsuit flyer vs. tree|Next Prev Swipe left/right Wingsuit flyer vs. tree Here’s your anxiety-induci...|Next Prev Swipe left/right Wingsuit flyer vs. tree Here's your anxiety-induci...|\n",
      "| Wikileaks Admits To Screwing Up IMMENSELY With Twitter Poll On Hillary’s Health| Wikileaks Admits To Screwing Up IMMENSELY With Twitter Poll On Hillary's Health|Wikileaks, which is more a conspiracy enterprise than it is a whistleblowing ...|Wikileaks, which is more a conspiracy enterprise than it is a whistleblowing ...|\n",
      "|    SOLID: 211,000 Jobs Created in April, Unemployment Falls to 4.4% - Breitbart|    SOLID: 211,000 Jobs Created in April, Unemployment Falls to 4.4% - Breitbart|The American job creation machine was   in April after a disappointing March....|The American job creation machine was in April after a disappointing March. P...|\n",
      "|IT JUST GOT REAL! GOP Rep. Jim Jordan Tells Judge Jeanine Key Players in anti...|IT JUST GOT REAL! GOP Rep. Jim Jordan Tells Judge Jeanine Key Players in anti...|One of the big players in trying to get to the truth about the bias against P...|One of the big players in trying to get to the truth about the bias against P...|\n",
      "|British PM May disagrees with U.S. decision to move embassy to Jerusalem: spo...|British PM May disagrees with U.S. decision to move embassy to Jerusalem: spo...|LONDON (Reuters) - British Prime Minister Theresa May disagrees with the U.S....|LONDON (Reuters) - British Prime Minister Theresa May disagrees with the U.S....|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply cleaning to title and text\n",
    "welfake_df_clean = welfake_df_dedup.withColumn(\"cleaned_title\", clean_text_udf(\"title\")) \\\n",
    "                       .withColumn(\"cleaned_text\", clean_text_udf(\"text\"))\n",
    "\n",
    "# Preview results\n",
    "welfake_df_clean.select(\"title\", \"cleaned_title\", \"text\", \"cleaned_text\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ae4e8",
   "metadata": {},
   "source": [
    "## 8. Remove null and empty string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd93599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=================================================>   (238 + 12) / 256]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty text rows: 1186\n",
      "After dataset size: 62492 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove null or empty string values\n",
    "welfake_df_processed = welfake_df_clean.filter(\n",
    "    (col(\"cleaned_text\").isNotNull()) & \n",
    "    (col(\"cleaned_text\") != \"\") &\n",
    "    (col(\"cleaned_title\").isNotNull()) & \n",
    "    (col(\"cleaned_title\") != \"\") &\n",
    "    (col(\"label\").isNotNull()) \n",
    ")\n",
    "\n",
    "# Count the number of rows with empty values removed\n",
    "clean_count = welfake_df_clean.count()\n",
    "processed_count = welfake_df_processed.count()\n",
    "removed_empty = clean_count - processed_count\n",
    "\n",
    "print(f\"Removed empty text rows: {removed_empty}\")\n",
    "print(f\"After dataset size: {processed_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad9481",
   "metadata": {},
   "source": [
    "## 9. Remove outlier based on text word count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91fed0",
   "metadata": {},
   "source": [
    "### 9.1. Calculate article text word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "993f73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|        cleaned_text|text_wc|\n",
      "+--------------------+-------+\n",
      "|Next Prev Swipe l...|     49|\n",
      "|Wikileaks, which ...|    523|\n",
      "|The American job ...|    257|\n",
      "+--------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nel/iti5202_big_data/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/home/nel/iti5202_big_data/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/home/nel/iti5202_big_data/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 642, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/home/nel/iti5202_big_data/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate text word count\n",
    "welfake_df_wc = welfake_df_processed.withColumn(\"text_wc\", size(split(col(\"cleaned_text\"), \"\\\\s+\")))\n",
    "\n",
    "welfake_df_wc.select(\"cleaned_text\", \"text_wc\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec9141",
   "metadata": {},
   "source": [
    "### 9.2. Remove outlier based on percentile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9233136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==================================================>  (245 + 11) / 256]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper tail (96% to 99%): [1409.0, 1517.0, 1688.0, 24173.0]\n",
      "Lower tail (1% to 4%): [1.0, 26.0, 40.0, 54.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate key percentiles for text word count\n",
    "percentiles_upper_tail = [0.96, 0.97, 0.98, 0.99]\n",
    "percentiles_lower_tail = [0.01, 0.02, 0.03, 0.04]\n",
    "\n",
    "# Compute percentiles\n",
    "upper_tail_quantiles = welfake_df_wc.approxQuantile(\"text_wc\", percentiles_upper_tail, 0.01)\n",
    "lower_tail_quantiles = welfake_df_wc.approxQuantile(\"text_wc\", percentiles_lower_tail, 0.01)\n",
    "\n",
    "# Show quantile values for analysis\n",
    "print(f\"Upper tail (96% to 99%): {upper_tail_quantiles}\")\n",
    "print(f\"Lower tail (1% to 4%): {lower_tail_quantiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6ba33a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out text_wc < 26 or > 1688\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=================================================>   (240 + 12) / 256]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed outlier text rows: 2832\n",
      "After dataset size: 59660 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate 2nd and 98th percentiles\n",
    "lower_bound = 26\n",
    "upper_bound = 1688\n",
    "\n",
    "print(f\"Filter out text_wc < {lower_bound} or > {upper_bound}\\n\")\n",
    "\n",
    "# Filter out values below the 2nd and above the 98th percentiles\n",
    "welfake_df_filtered = welfake_df_wc.filter(\n",
    "    (F.col(\"text_wc\") > lower_bound) & (F.col(\"text_wc\") < upper_bound)\n",
    ")\n",
    "\n",
    "# Count the number of rows with empty values removed\n",
    "outlier_count = welfake_df_filtered.count()\n",
    "removed_outlier = processed_count - outlier_count\n",
    "\n",
    "print(f\"Removed outlier text rows: {removed_outlier}\")\n",
    "print(f\"After dataset size: {outlier_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c4212e",
   "metadata": {},
   "source": [
    "## 10. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db71bda",
   "metadata": {},
   "source": [
    "### 10.1. Create quantity feature columns using FeaturesSpark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19dd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise FeaturesSpark\n",
    "feat_spark = FeaturesSpark()\n",
    "\n",
    "# Create quantity feature columns\n",
    "welfake_df_feat_spark = feat_spark.transform(df=welfake_df_filtered, text_col=\"cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e40bcee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+-----+\n",
      "|       cleaned_title|        cleaned_text|num_characters|num_special_characters|num_capital_letters|num_words|num_sentences|words_per_sentence|num_short_sentences|num_long_sentences|label|\n",
      "+--------------------+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+-----+\n",
      "|Wingsuit flyer vs...|Next Prev Swipe l...|           286|                     9|                  9|       49|            5|               9.8|                  4|                 1|    1|\n",
      "|Wikileaks Admits ...|Wikileaks, which ...|          3116|                    71|                 63|      523|           27| 19.37037037037037|                  7|                11|    1|\n",
      "|SOLID: 211,000 Jo...|The American job ...|          1474|                    39|                 25|      257|           20|             12.85|                  7|                 6|    0|\n",
      "|IT JUST GOT REAL!...|One of the big pl...|          2820|                    87|                263|      482|           31|15.548387096774194|                 13|                11|    1|\n",
      "|British PM May di...|LONDON (Reuters) ...|          1342|                    27|                 54|      211|           15|14.066666666666666|                  6|                 5|    0|\n",
      "+--------------------+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preview quanitty feature columns\n",
    "welfake_df_feat_spark.select(\n",
    "    \"cleaned_title\",\n",
    "    \"cleaned_text\",\n",
    "    \"num_characters\",\n",
    "    \"num_special_characters\",\n",
    "    \"num_capital_letters\",\n",
    "    \"num_words\",\n",
    "    \"num_sentences\",\n",
    "    \"words_per_sentence\",\n",
    "    \"num_short_sentences\",\n",
    "    \"num_long_sentences\",\n",
    "    \"label\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd1739",
   "metadata": {},
   "source": [
    "### 10.2. Create POS feature columns using POSFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3cfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise POSFeatures\n",
    "pos_features = POSFeatures()\n",
    "\n",
    "# Create POS feature columns\n",
    "welfake_df_pos_feat = pos_features.transform(df=welfake_df_feat_spark, text_col=\"cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e331221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+---------+--------------+-----------+---------------+-----+\n",
      "|       cleaned_title|        cleaned_text|num_nouns|num_verbs|num_adjectives|num_adverbs|num_determiners|label|\n",
      "+--------------------+--------------------+---------+---------+--------------+-----------+---------------+-----+\n",
      "|Wingsuit flyer vs...|Next Prev Swipe l...|       13|        7|             3|          5|              8|    1|\n",
      "|Wikileaks Admits ...|Wikileaks, which ...|       98|       86|            26|         39|             51|    1|\n",
      "|SOLID: 211,000 Jo...|The American job ...|       66|       25|            16|         17|             25|    0|\n",
      "|IT JUST GOT REAL!...|One of the big pl...|       65|       61|            31|         19|             54|    1|\n",
      "|British PM May di...|LONDON (Reuters) ...|       39|       25|            19|          5|             23|    0|\n",
      "+--------------------+--------------------+---------+---------+--------------+-----------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preview POS feature columns\n",
    "welfake_df_pos_feat.select(\n",
    "    \"cleaned_title\",\n",
    "    \"cleaned_text\",\n",
    "    \"num_nouns\",\n",
    "    \"num_verbs\",\n",
    "    \"num_adjectives\",\n",
    "    \"num_adverbs\",\n",
    "    \"num_determiners\",\n",
    "    \"label\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e9a8b",
   "metadata": {},
   "source": [
    "### 10.3. Create Readability features using ReadabilityIndices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a57a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise ReadabilityIndices\n",
    "readability = ReadabilityIndices()\n",
    "\n",
    "# Create readability feature columns\n",
    "welfake_df_readability = readability.extract_features(welfake_df_pos_feat, \"cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c42ee50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+---------+---------+-------------+-----+\n",
      "|       cleaned_title|        cleaned_text|gunning_fog|     smog|      ari|num_syllables|label|\n",
      "+--------------------+--------------------+-----------+---------+---------+-------------+-----+\n",
      "|Wingsuit flyer vs...|Next Prev Swipe l...|   9.797959|10.125756| 7.572143|         72.0|    1|\n",
      "|Wikileaks Admits ...|Wikileaks, which ...|  14.012308|13.412044|12.330879|        823.0|    1|\n",
      "|SOLID: 211,000 Jo...|The American job ...|   9.757804|10.504224|  8.03099|        393.0|    0|\n",
      "|IT JUST GOT REAL!...|One of the big pl...|  13.243241|13.445107|11.795769|        757.0|    1|\n",
      "|British PM May di...|LONDON (Reuters) ...|  15.636364|14.937675| 13.38427|        374.0|    0|\n",
      "+--------------------+--------------------+-----------+---------+---------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preview readability columns\n",
    "welfake_df_readability.select(\n",
    "    \"cleaned_title\",\n",
    "    \"cleaned_text\",\n",
    "    \"gunning_fog\",\n",
    "    \"smog\",\n",
    "    \"ari\",\n",
    "    \"num_syllables\",\n",
    "    \"label\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e374af1",
   "metadata": {},
   "source": [
    "### 10.4. Create psycholinguistics features using Psycholinguistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be84a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create psycholinguistics feature columns\n",
    "welfake_df_psycho = Psycholinguistics.extract_features(\n",
    "    df=welfake_df_readability,\n",
    "    text_col=\"cleaned_text\",\n",
    "    title_col=\"cleaned_title\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c441448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+----------------+-----+\n",
      "|        cleaned_text|     polarity|subjectivity|title_similarity|label|\n",
      "+--------------------+-------------+------------+----------------+-----+\n",
      "|Next Prev Swipe l...|        0.225|  0.49166667|       0.0952381|    1|\n",
      "|Wikileaks, which ...| -0.036196146|  0.49321994|     0.026578072|    1|\n",
      "|The American job ...| 0.0031045752|  0.37385622|     0.029940119|    0|\n",
      "|One of the big pl...|-0.0028036176|  0.43458655|      0.04262295|    1|\n",
      "|LONDON (Reuters) ...|  -0.03263889|  0.50208336|        0.078125|    0|\n",
      "+--------------------+-------------+------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preview psycholinguistics columns\n",
    "welfake_df_psycho.select(\n",
    "    \"cleaned_text\",\n",
    "    \"polarity\",\n",
    "    \"subjectivity\",\n",
    "    \"title_similarity\",\n",
    "    \"label\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09cf2c",
   "metadata": {},
   "source": [
    "### 10.5. Extract engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "673df91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cleaned_text: string, num_characters: int, num_special_characters: int, num_capital_letters: int, num_words: int, num_sentences: int, words_per_sentence: double, num_short_sentences: int, num_long_sentences: int, num_nouns: int, num_verbs: int, num_adjectives: int, num_adverbs: int, num_determiners: int, gunning_fog: float, smog: float, ari: float, num_syllables: float, polarity: float, subjectivity: float, title_similarity: float, label: int]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature columns for machine learning\n",
    "welfake_df_preprocessed = welfake_df_psycho.select(\n",
    "    \"cleaned_text\",\n",
    "    \"num_characters\",\n",
    "    \"num_special_characters\",\n",
    "    \"num_capital_letters\",\n",
    "    \"num_words\",\n",
    "    \"num_sentences\",\n",
    "    \"words_per_sentence\",\n",
    "    \"num_short_sentences\",\n",
    "    \"num_long_sentences\",\n",
    "    \"num_nouns\",\n",
    "    \"num_verbs\",\n",
    "    \"num_adjectives\",\n",
    "    \"num_adverbs\",\n",
    "    \"num_determiners\",\n",
    "    \"gunning_fog\",\n",
    "    \"smog\",\n",
    "    \"ari\",\n",
    "    \"num_syllables\",\n",
    "    \"polarity\",\n",
    "    \"subjectivity\",\n",
    "    \"title_similarity\",\n",
    "    \"label\"\n",
    ")\n",
    "\n",
    "# Cache results\n",
    "welfake_df_preprocessed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba9f61eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+---------+---------+--------------+-----------+---------------+-----------+---------+---------+-------------+-------------+------------+----------------+-----+\n",
      "|        cleaned_text|num_characters|num_special_characters|num_capital_letters|num_words|num_sentences|words_per_sentence|num_short_sentences|num_long_sentences|num_nouns|num_verbs|num_adjectives|num_adverbs|num_determiners|gunning_fog|     smog|      ari|num_syllables|     polarity|subjectivity|title_similarity|label|\n",
      "+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+---------+---------+--------------+-----------+---------------+-----------+---------+---------+-------------+-------------+------------+----------------+-----+\n",
      "|Next Prev Swipe l...|           286|                     9|                  9|       49|            5|               9.8|                  4|                 1|       13|        7|             3|          5|              8|   9.797959|10.125756| 7.572143|         72.0|        0.225|  0.49166667|       0.0952381|    1|\n",
      "|Wikileaks, which ...|          3116|                    71|                 63|      523|           27| 19.37037037037037|                  7|                11|       98|       86|            26|         39|             51|  14.012308|13.412044|12.330879|        823.0| -0.036196146|  0.49321994|     0.026578072|    1|\n",
      "|The American job ...|          1474|                    39|                 25|      257|           20|             12.85|                  7|                 6|       66|       25|            16|         17|             25|   9.757804|10.504224|  8.03099|        393.0| 0.0031045752|  0.37385622|     0.029940119|    0|\n",
      "|One of the big pl...|          2820|                    87|                263|      482|           31|15.548387096774194|                 13|                11|       65|       61|            31|         19|             54|  13.243241|13.445107|11.795769|        757.0|-0.0028036176|  0.43458655|      0.04262295|    1|\n",
      "|LONDON (Reuters) ...|          1342|                    27|                 54|      211|           15|14.066666666666666|                  6|                 5|       39|       25|            19|          5|             23|  15.636364|14.937675| 13.38427|        374.0|  -0.03263889|  0.50208336|        0.078125|    0|\n",
      "+--------------------+--------------+----------------------+-------------------+---------+-------------+------------------+-------------------+------------------+---------+---------+--------------+-----------+---------------+-----------+---------+---------+-------------+-------------+------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preview preprocessed data\n",
    "welfake_df_preprocessed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ffa3b",
   "metadata": {},
   "source": [
    "# 11. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb834f",
   "metadata": {},
   "source": [
    "## Classic ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42a6aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 47605, Test samples: 12055\n",
      "Training Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.7865, F1: 0.7847, AUC: 0.8441\n",
      "Training Decision Tree...\n",
      "Decision Tree - Accuracy: 0.7831, F1: 0.7795, AUC: 0.5033\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.8096, F1: 0.8074, AUC: 0.8882\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting - Accuracy: 0.8158, F1: 0.8143, AUC: 0.8932\n",
      "Training Naive Bayes...\n",
      "Naive Bayes - Accuracy: 0.5736, F1: 0.5594, AUC: 0.5984\n",
      "\n",
      "================================================================================\n",
      "Model                Accuracy   Precision  Recall     F1         AUC       \n",
      "================================================================================\n",
      "Logistic Regression  0.7865     0.7862     0.7865     0.7847     0.8441    \n",
      "Decision Tree        0.7831     0.7854     0.7831     0.7795     0.5033    \n",
      "Random Forest        0.8096     0.8110     0.8096     0.8074     0.8882    \n",
      "Gradient Boosting    0.8158     0.8162     0.8158     0.8143     0.8932    \n",
      "Naive Bayes          0.5736     0.6313     0.5736     0.5594     0.5984    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, DecisionTreeClassifier, RandomForestClassifier,\n",
    "    GBTClassifier, NaiveBayes\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# Define features\n",
    "feature_cols = [\n",
    " 'num_characters',\n",
    " 'num_special_characters',\n",
    " 'num_capital_letters',\n",
    " 'num_words',\n",
    " 'num_sentences',\n",
    " 'words_per_sentence',\n",
    " 'num_short_sentences',\n",
    " 'num_long_sentences',\n",
    " 'num_nouns',\n",
    " 'num_verbs',\n",
    " 'num_adjectives',\n",
    " 'num_adverbs',\n",
    " 'num_determiners',\n",
    " 'gunning_fog',\n",
    " 'smog',\n",
    " 'ari',\n",
    " 'num_syllables',\n",
    " 'polarity',\n",
    " 'subjectivity',\n",
    " 'title_similarity',\n",
    "]\n",
    "\n",
    "# Pre-process data once and persist\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\", handleInvalid=\"skip\")\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "# Create preprocessing pipeline and apply once\n",
    "preprocessing_pipeline = Pipeline(stages=[assembler, scaler])\n",
    "preprocessing_model = preprocessing_pipeline.fit(welfake_df_preprocessed)\n",
    "processed_df = preprocessing_model.transform(welfake_df_preprocessed)\n",
    "\n",
    "# Train/test split on preprocessed data\n",
    "train_df, test_df = processed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Persist with default storage level (faster alternative)\n",
    "train_df.cache()\n",
    "test_df.cache()\n",
    "\n",
    "# Force materialization\n",
    "train_count = train_df.count()\n",
    "test_count = test_df.count()\n",
    "print(f\"Train samples: {train_count}, Test samples: {test_count}\")\n",
    "\n",
    "# Optimized models with reduced complexity for speed\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"label\", \n",
    "        maxIter=50,  # Reduced from 100\n",
    "        regParam=0.01,\n",
    "        elasticNetParam=0.1\n",
    "    ),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"label\",\n",
    "        maxDepth=10,  # Limit depth\n",
    "        maxBins=32    # Reduce bins for speed\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"label\", \n",
    "        numTrees=50,      # Reduced from 100\n",
    "        maxDepth=10,      # Limit depth\n",
    "        subsamplingRate=0.8,\n",
    "        featureSubsetStrategy=\"sqrt\"\n",
    "    ),\n",
    "    \"Gradient Boosting\": GBTClassifier(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"label\", \n",
    "        maxIter=50,       # Reduced from 100\n",
    "        maxDepth=5,       # Reduced depth\n",
    "        stepSize=0.1\n",
    "    ),\n",
    "    \"Naive Bayes\": NaiveBayes(\n",
    "        featuresCol=\"features\", \n",
    "        labelCol=\"label\", \n",
    "        modelType=\"gaussian\",\n",
    "        smoothing=1.0\n",
    "    )\n",
    "}\n",
    "\n",
    "# Pre-create evaluators\n",
    "bin_eval = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    rawPredictionCol=\"rawPrediction\", \n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Single stage pipeline (preprocessing already done)\n",
    "    pipeline = Pipeline(stages=[clf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.transform(test_df)\n",
    "    \n",
    "    # Persist predictions for multiple evaluations\n",
    "    preds.cache()\n",
    "    \n",
    "    # Evaluate all metrics on cached predictions\n",
    "    acc = acc_eval.evaluate(preds)\n",
    "    f1 = f1_eval.evaluate(preds)\n",
    "    precision = precision_eval.evaluate(preds)\n",
    "    recall = recall_eval.evaluate(preds)\n",
    "    auc = bin_eval.evaluate(preds)\n",
    "    \n",
    "    results.append((name, acc, precision, recall, f1, auc))\n",
    "    print(f\"{name} - Accuracy: {acc:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Unpersist predictions to free memory\n",
    "    preds.unpersist()\n",
    "\n",
    "# Unpersist datasets\n",
    "train_df.unpersist()\n",
    "test_df.unpersist()\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'AUC':<10}\")\n",
    "print(\"=\"*80)\n",
    "for result in results:\n",
    "    name, acc, precision, recall, f1, auc = result\n",
    "    print(f\"{name:<20} {acc:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {auc:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1204b",
   "metadata": {},
   "source": [
    "## WELFake Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15efba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark implementation of your 2-stage WELFake-style system\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, StopWordsRemover, NGram, CountVectorizer, IDF,\n",
    "    VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# Assumptions:\n",
    "# - df (Spark DataFrame) has columns: cleaned_text (string), label (0/1),\n",
    "#   and all 20 LFS numeric columns you listed (already computed).\n",
    "# - Binary classification (0=real, 1=fake). LinearSVC works for binary labels.\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# ===== 0) Basic hygiene ===============================================================\n",
    "df = welfake_df_preprocessed  # your Spark DataFrame\n",
    "# Cast label to double and ensure no nulls in text/LFS\n",
    "df = (df\n",
    "      .withColumn(\"label\", F.col(\"label\").cast(\"double\"))\n",
    "      .withColumn(\"cleaned_text\", F.coalesce(F.col(\"cleaned_text\"), F.lit(\"\"))))\n",
    "\n",
    "# The 20 features total (adjust names to match your frame if needed)\n",
    "# feature_cols = [\n",
    "#     'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "#     'gunning_fog', 'smog', 'ari',\n",
    "#     'polarity', 'title_similarity', 'subjectivity',\n",
    "#     'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "#     'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "# ]\n",
    "\n",
    "feature_cols = [\n",
    "#  'num_characters',\n",
    " 'num_special_characters',\n",
    " 'num_capital_letters',\n",
    " 'num_words',\n",
    " 'num_sentences',\n",
    " 'words_per_sentence',\n",
    " 'num_short_sentences',\n",
    " 'num_long_sentences',\n",
    "#  'num_nouns',\n",
    " 'num_verbs',\n",
    " 'num_adjectives',\n",
    " 'num_adverbs',\n",
    " 'num_determiners',\n",
    " 'gunning_fog',\n",
    " 'smog',\n",
    " 'ari',\n",
    " 'num_syllables',\n",
    " 'polarity',\n",
    " 'subjectivity',\n",
    " 'title_similarity',\n",
    "]\n",
    "\n",
    "for c in feature_cols:\n",
    "    df = df.withColumn(c, F.col(c).cast(\"double\"))\n",
    "df = df.fillna(0, subset=feature_cols)\n",
    "\n",
    "# Your LFS splits (can be tweaked)\n",
    "LFS1 = ['num_special_characters', 'num_determiners', 'num_capital_letters', 'gunning_fog', 'polarity', 'num_syllables']\n",
    "# LFS2 = ['num_short_sentences', 'smog', 'title_similarity', 'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity', 'subjectivity', 'num_words']\n",
    "# LFS3 = ['num_long_sentences', 'ari', 'num_articles', 'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_verbs', 'num_sentences', 'words_per_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "229f53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Stratified split (approx) ===================================================\n",
    "# Keep class balance similar to scikit-learn's stratify\n",
    "# Create a stable row id to separate train/test\n",
    "df = df.withColumn(\"_row_id\", F.monotonically_increasing_id())\n",
    "\n",
    "test_frac = 0.30\n",
    "label_vals = [r[0] for r in df.select(\"label\").distinct().collect()]\n",
    "fractions = {float(k): test_frac for k in label_vals}\n",
    "test_df = df.sampleBy(\"label\", fractions=fractions, seed=42)\n",
    "train_df = df.join(test_df.select(\"_row_id\"), on=\"_row_id\", how=\"left_anti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58a6d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ===== 2) Base text pipeline: tokens -> (uni,bigram) -> CV -> TF-IDF ==================\n",
    "# Tokenize + stopword removal\n",
    "tok = RegexTokenizer(inputCol=\"cleaned_text\", outputCol=\"tokens\", pattern=\"\\\\W+\", toLowercase=True)\n",
    "sw = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_sw\")\n",
    "\n",
    "# 2-grams\n",
    "bi = NGram(n=2, inputCol=\"tokens_sw\", outputCol=\"bigrams\")\n",
    "\n",
    "# CountVectorizer for unigrams and bigrams (vocabSize similar to max_features=5000)\n",
    "cv_uni = CountVectorizer(inputCol=\"tokens_sw\", outputCol=\"tf_uni\", vocabSize=5000, minDF=2)\n",
    "cv_bi  = CountVectorizer(inputCol=\"bigrams\",  outputCol=\"tf_bi\",  vocabSize=5000, minDF=2)\n",
    "\n",
    "# Concatenate uni+bi into \"cv_features\"\n",
    "cv_asm = VectorAssembler(inputCols=[\"tf_uni\", \"tf_bi\"], outputCol=\"cv_features\")\n",
    "\n",
    "# TF-IDF over the same tf (use IDF on the combined term-freqs)\n",
    "idf = IDF(inputCol=\"cv_features\", outputCol=\"tfidf_features\", minDocFreq=2)\n",
    "\n",
    "text_pipe = Pipeline(stages=[tok, sw, bi, cv_uni, cv_bi, cv_asm, idf])\n",
    "text_model = text_pipe.fit(train_df)\n",
    "train_tx = text_model.transform(train_df).cache()\n",
    "test_tx  = text_model.transform(test_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0188717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 3) Helper to train one SVM on (CV ⊕ scaled LFS) — make columns unique\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "def train_lfs_enabled_svm(lfs_cols, stub):\n",
    "    # stub e.g. \"pred1\", \"pred2\", \"pred3\"\n",
    "    lfs_vec   = VectorAssembler(inputCols=lfs_cols, outputCol=f\"{stub}_lfs_vec\")\n",
    "    lfs_scale = StandardScaler(inputCol=f\"{stub}_lfs_vec\", outputCol=f\"{stub}_lfs_scaled\",\n",
    "                               withStd=True, withMean=True)\n",
    "    feat_asm  = VectorAssembler(inputCols=[\"cv_features\", f\"{stub}_lfs_scaled\"], outputCol=f\"{stub}_features\")\n",
    "\n",
    "    svm = LinearSVC(\n",
    "        featuresCol=f\"{stub}_features\",\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=stub,                  # e.g., pred1\n",
    "        rawPredictionCol=f\"{stub}_raw\",      # e.g., pred1_raw  <<< UNIQUE!\n",
    "        maxIter=100, regParam=0.1\n",
    "    )\n",
    "    return Pipeline(stages=[lfs_vec, lfs_scale, feat_asm, svm]).fit(train_tx)\n",
    "\n",
    "# Train the three LFS-enabled SVMs\n",
    "svm1_model = train_lfs_enabled_svm(LFS1, \"pred1\")\n",
    "svm2_model = train_lfs_enabled_svm(LFS2, \"pred2\")\n",
    "svm3_model = train_lfs_enabled_svm(LFS3, \"pred3\")\n",
    "\n",
    "# Transform sequentially (now no column name clashes)\n",
    "preds = svm1_model.transform(test_tx)\n",
    "preds = svm2_model.transform(preds)\n",
    "preds = svm3_model.transform(preds)\n",
    "\n",
    "# Stage-1 vote\n",
    "from pyspark.sql import functions as F\n",
    "preds = preds.withColumn(\n",
    "    \"P6\", F.when((F.col(\"pred1\") + F.col(\"pred2\") + F.col(\"pred3\")) >= 2.0, 1.0).otherwise(0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc6c8120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6365:=============================================>     (229 + 12) / 256]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 4) CV-only and TF-IDF-only SVMs — also give unique rawPredictionCol\n",
    "svm_cv = LinearSVC(\n",
    "    featuresCol=\"cv_features\", labelCol=\"label\",\n",
    "    predictionCol=\"pred_cv\", rawPredictionCol=\"raw_cv\",\n",
    "    maxIter=100, regParam=0.1\n",
    ")\n",
    "svm_ti = LinearSVC(\n",
    "    featuresCol=\"tfidf_features\", labelCol=\"label\",\n",
    "    predictionCol=\"pred_tfidf\", rawPredictionCol=\"raw_tfidf\",\n",
    "    maxIter=100, regParam=0.1\n",
    ")\n",
    "\n",
    "svm_cv_model = svm_cv.fit(train_tx)\n",
    "svm_ti_model = svm_ti.fit(train_tx)\n",
    "\n",
    "preds = svm_cv_model.transform(preds)\n",
    "preds = svm_ti_model.transform(preds)\n",
    "\n",
    "# Final vote across {P6, pred_cv, pred_tfidf}\n",
    "preds = preds.withColumn(\n",
    "    \"final_pred\",\n",
    "    F.when((F.col(\"P6\") + F.col(\"pred_cv\") + F.col(\"pred_tfidf\")) >= 2.0, 1.0).otherwise(0.0)\n",
    ")\n",
    "\n",
    "# Accuracy\n",
    "acc = preds.select((F.col(\"final_pred\") == F.col(\"label\")).cast(\"double\").alias(\"correct\")) \\\n",
    "           .agg(F.avg(\"correct\").alias(\"accuracy\")).collect()[0][\"accuracy\"]\n",
    "print(f\"Final Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welfake-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
