{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04300ecf",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d02bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bachtiarherdianto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bachtiarherdianto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import textstat\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627bb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        pos_tags = pos_tag(words)\n",
    "        \n",
    "        # Writing pattern\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
    "        num_determinants = sum(1 for w in words if w.lower() in ['the', 'a', 'an'])\n",
    "        num_capital_letters = sum(1 for c in text if c.isupper())\n",
    "        num_short_sentences = sum(1 for s in sentences if len(s.split()) < 10)\n",
    "        num_long_sentences = sum(1 for s in sentences if len(s.split()) > 20)\n",
    "\n",
    "        # Readability indices\n",
    "        gunning_fog = textstat.gunning_fog(text)\n",
    "        smog = textstat.smog_index(text)\n",
    "        ari = textstat.automated_readability_index(text)\n",
    "\n",
    "        # Psycholinguistics\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        title_similarity = 0  # Optional, you can compute this with cosine or Jaccard if you have 'title'\n",
    "\n",
    "        # Quantity\n",
    "        num_syllables = textstat.syllable_count(text)\n",
    "        num_words = len(words)\n",
    "        num_sentences = len([s for s in sentences if s.strip()])\n",
    "        num_adjectives = sum(1 for _, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS'])\n",
    "        num_adverbs = sum(1 for _, tag in pos_tags if tag in ['RB', 'RBR', 'RBS'])\n",
    "        num_verbs = sum(1 for _, tag in pos_tags if tag.startswith('VB'))\n",
    "        num_articles = sum(1 for w in words if w.lower() in ['a', 'an', 'the'])\n",
    "\n",
    "        rate_adj_adv = (num_adjectives + num_adverbs) / num_words if num_words > 0 else 0\n",
    "        words_per_sentence = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "        return pd.Series([\n",
    "            num_special_chars, num_determinants, num_capital_letters, num_short_sentences, num_long_sentences,\n",
    "            gunning_fog, smog, ari,\n",
    "            polarity, title_similarity, subjectivity,\n",
    "            num_syllables, num_words, rate_adj_adv, words_per_sentence,\n",
    "            num_articles, num_verbs, num_sentences, num_adjectives, num_adverbs\n",
    "        ])\n",
    "    except:\n",
    "        return pd.Series([None]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e6a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21354</th>\n",
       "      <td>17322</td>\n",
       "      <td>Trump's choice for U.S. attorney general says ...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President-elect Do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>21871</td>\n",
       "      <td>Alison Wright, Exiled From 'The Americans' (Pe...</td>\n",
       "      <td>It took Alison Wright 34 years to land her fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>32704</td>\n",
       "      <td>Kurdistan supervisors begin counting votes in ...</td>\n",
       "      <td>ERBIL, Iraq (Reuters) - Voting stations set up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24177</th>\n",
       "      <td>35894</td>\n",
       "      <td>New Saudi king ascends to the throne as terror...</td>\n",
       "      <td>At 3 a.m. on a cold desert night earlier this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>24368</td>\n",
       "      <td>May shook on gentlemen's agreement on Brexit d...</td>\n",
       "      <td>BRUSSELS (Reuters) - An interim Brexit deal st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                      cleaned_title  \\\n",
       "21354  17322  Trump's choice for U.S. attorney general says ...   \n",
       "25012  21871  Alison Wright, Exiled From 'The Americans' (Pe...   \n",
       "9901   32704  Kurdistan supervisors begin counting votes in ...   \n",
       "24177  35894  New Saudi king ascends to the throne as terror...   \n",
       "37552  24368  May shook on gentlemen's agreement on Brexit d...   \n",
       "\n",
       "                                            cleaned_text  label  \n",
       "21354  WASHINGTON (Reuters) - U.S. President-elect Do...      0  \n",
       "25012  It took Alison Wright 34 years to land her fir...      0  \n",
       "9901   ERBIL, Iraq (Reuters) - Voting stations set up...      0  \n",
       "24177  At 3 a.m. on a cold desert night earlier this ...      0  \n",
       "37552  BRUSSELS (Reuters) - An interim Brexit deal st...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_welfake.csv')\n",
    "\n",
    "# # Sample 50% from each class\n",
    "# df_sampled = df.groupby('label', group_keys=False).sample(frac=0.5, random_state=42)\n",
    "\n",
    "# Sample 2 rows per class\n",
    "df_sampled = df.groupby('label', group_keys=False).sample(n=100, random_state=42)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95a2582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200 entries, 21354 to 54745\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   index                200 non-null    int64  \n",
      " 1   cleaned_title        200 non-null    object \n",
      " 2   cleaned_text         200 non-null    object \n",
      " 3   label                200 non-null    int64  \n",
      " 4   num_special_chars    200 non-null    float64\n",
      " 5   num_determinants     200 non-null    float64\n",
      " 6   num_capital_letters  200 non-null    float64\n",
      " 7   num_short_sentences  200 non-null    float64\n",
      " 8   num_long_sentences   200 non-null    float64\n",
      " 9   gunning_fog          200 non-null    float64\n",
      " 10  smog                 200 non-null    float64\n",
      " 11  ari                  200 non-null    float64\n",
      " 12  polarity             200 non-null    float64\n",
      " 13  title_similarity     200 non-null    float64\n",
      " 14  subjectivity         200 non-null    float64\n",
      " 15  num_syllables        200 non-null    float64\n",
      " 16  num_words            200 non-null    float64\n",
      " 17  rate_adj_adv         200 non-null    float64\n",
      " 18  words_per_sentence   200 non-null    float64\n",
      " 19  num_articles         200 non-null    float64\n",
      " 20  num_verbs            200 non-null    float64\n",
      " 21  num_sentences        200 non-null    float64\n",
      " 22  num_adjectives       200 non-null    float64\n",
      " 23  num_adverbs          200 non-null    float64\n",
      "dtypes: float64(20), int64(2), object(2)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called df and has a 'text' column\n",
    "feature_columns = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# # Apply feature extraction and add prefix to the resulting columns\n",
    "# df_sampled[text_feature_cols := ['text_' + col for col in feature_columns]] = (\n",
    "#     df_sampled['cleaned_text'].apply(extract_features)\n",
    "# )\n",
    "\n",
    "# # Apply feature extraction and add prefix to the resulting columns\n",
    "# df_sampled[title_feature_cols := ['title_' + col for col in feature_columns]] = (\n",
    "#     df_sampled['cleaned_title'].apply(extract_features)\n",
    "# )\n",
    "\n",
    "df_sampled[feature_columns] = df_sampled['cleaned_text'].apply(extract_features)\n",
    "\n",
    "df_sampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1c8b4",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdada038",
   "metadata": {},
   "source": [
    "#### Pandas Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ca3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bccfef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "# text_feature_cols + title_feature_cols\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "X = df_sampled[feature_cols]\n",
    "y = df_sampled['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8ef76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "1                  SVM     0.825\n",
      "9  Logistic Regression     0.825\n",
      "4              Bagging     0.725\n",
      "6        Random Forest     0.725\n",
      "8          Extra Trees     0.725\n",
      "0                  KNN     0.675\n",
      "5             AdaBoost     0.675\n",
      "2          Naive Bayes     0.650\n",
      "3        Decision Tree     0.650\n",
      "7    Gradient Boosting     0.650\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "    # print(f\"✅ {name} Accuracy: {acc:.4f}\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy_df = pd.DataFrame([\n",
    "    {'Model': name, 'Accuracy': result['accuracy']}\n",
    "    for name, result in results.items()\n",
    "])\n",
    "print(accuracy_df.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "feature_cols = [\n",
    "# text_feature_cols + title_feature_cols\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7356f845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8983333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf0da7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b309f5",
   "metadata": {},
   "source": [
    "#### Pyspark Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a272b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/bachtiarherdianto/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "25/08/18 16:36:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/18 16:36:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session (only once)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fake News Detection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dfdd134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Model              |Accuracy          |Precision         |Recall            |F1                |AUC                |\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Random Forest      |0.6585365853658537|0.6757973733583489|0.6585365853658537|0.652350653941322 |0.7714285714285715 |\n",
      "|Decision Tree      |0.6097560975609756|0.6333422674886089|0.6097560975609756|0.5963653754184601|0.48571428571428565|\n",
      "|Logistic Regression|0.6097560975609756|0.6228893058161351|0.6097560975609756|0.6026864616472252|0.7119047619047618 |\n",
      "|Gradient Boosting  |0.5853658536585366|0.6002710027100271|0.5853658536585366|0.5747794499221588|0.65               |\n",
      "|Naive Bayes        |0.5609756097560976|0.561219512195122 |0.5609756097560976|0.5556733828207847|0.519047619047619  |\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, DecisionTreeClassifier, RandomForestClassifier,\n",
    "    GBTClassifier, NaiveBayes\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Define features\n",
    "feature_cols = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# Assemble features into vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "from pyspark.sql import Row\n",
    "spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Models available in Spark MLlib\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100),\n",
    "    \"Gradient Boosting\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"gaussian\")\n",
    "}\n",
    "\n",
    "# Evaluators\n",
    "bin_eval = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, clf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    preds = model.transform(test_df)\n",
    "\n",
    "    acc = multi_eval.setMetricName(\"accuracy\").evaluate(preds)\n",
    "    f1 = multi_eval.setMetricName(\"f1\").evaluate(preds)\n",
    "    precision = multi_eval.setMetricName(\"weightedPrecision\").evaluate(preds)\n",
    "    recall = multi_eval.setMetricName(\"weightedRecall\").evaluate(preds)\n",
    "    auc = bin_eval.evaluate(preds)\n",
    "\n",
    "    results.append((name, acc, precision, recall, f1, auc))\n",
    "\n",
    "# Convert results to Spark DataFrame\n",
    "results_df = spark.createDataFrame(results, [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
    "results_df.orderBy(\"Accuracy\", ascending=False).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93e947ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.652351</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.622889</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.602686</td>\n",
       "      <td>0.711905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.633342</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.596365</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.600271</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.574779</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.561220</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.555673</td>\n",
       "      <td>0.519048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall        F1       AUC\n",
       "2        Random Forest  0.658537   0.675797  0.658537  0.652351  0.771429\n",
       "0  Logistic Regression  0.609756   0.622889  0.609756  0.602686  0.711905\n",
       "1        Decision Tree  0.609756   0.633342  0.609756  0.596365  0.485714\n",
       "3    Gradient Boosting  0.585366   0.600271  0.585366  0.574779  0.650000\n",
       "4          Naive Bayes  0.560976   0.561220  0.560976  0.555673  0.519048"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"]).sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6d42f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Model                  |Accuracy          |Precision         |Recall            |F1                |AUC                |\n",
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Linear SVM             |0.7073170731707317|0.7287054409005629|0.7073170731707317|0.702014846235419 |0.7523809523809524 |\n",
      "|Random Forest          |0.6585365853658537|0.6757973733583489|0.6585365853658537|0.652350653941322 |0.7714285714285715 |\n",
      "|Decision Tree          |0.6097560975609756|0.6333422674886089|0.6097560975609756|0.5963653754184601|0.48571428571428565|\n",
      "|Logistic Regression    |0.6097560975609756|0.6228893058161351|0.6097560975609756|0.6026864616472252|0.7119047619047618 |\n",
      "|Gradient Boosting (GBT)|0.5853658536585366|0.6002710027100271|0.5853658536585366|0.5747794499221588|0.65               |\n",
      "|Naive Bayes            |0.5609756097560976|0.561219512195122 |0.5609756097560976|0.5556733828207847|0.519047619047619  |\n",
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, DecisionTreeClassifier, RandomForestClassifier,\n",
    "    GBTClassifier, NaiveBayes, LinearSVC\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# ✅ Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"Fake News Detection PySpark4\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "if \"pandas\" in str(type(df_sampled)):\n",
    "    try:\n",
    "        spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "    except Exception:\n",
    "        # fallback for Pandas >= 2.0\n",
    "        spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "else:\n",
    "    spark_df = df_sampled\n",
    "\n",
    "# ✅ Cast label to integer (required for MLlib)\n",
    "spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "# ✅ Features\n",
    "feature_cols = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "# ✅ Split train/test\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# ✅ Models (all supported in PySpark 4.0)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100),\n",
    "    \"Gradient Boosting (GBT)\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"gaussian\"),\n",
    "    \"Linear SVM\": LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.01)\n",
    "}\n",
    "\n",
    "# ✅ Evaluators\n",
    "bin_eval = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, clf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    preds = model.transform(test_df)\n",
    "\n",
    "    acc = multi_eval.setMetricName(\"accuracy\").evaluate(preds)\n",
    "    f1 = multi_eval.setMetricName(\"f1\").evaluate(preds)\n",
    "    precision = multi_eval.setMetricName(\"weightedPrecision\").evaluate(preds)\n",
    "    recall = multi_eval.setMetricName(\"weightedRecall\").evaluate(preds)\n",
    "    auc = bin_eval.evaluate(preds)\n",
    "\n",
    "    results.append((name, acc, precision, recall, f1, auc))\n",
    "\n",
    "# ✅ Show Results\n",
    "results_df = spark.createDataFrame(results, [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
    "results_df.orderBy(\"Accuracy\", ascending=False).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "if \"pandas\" in str(type(df_sampled)):\n",
    "    try:\n",
    "        spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "    except Exception:\n",
    "        # fallback for Pandas >= 2.0\n",
    "        spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "else:\n",
    "    spark_df = df_sampled\n",
    "\n",
    "# ✅ Cast label to integer (required for MLlib)\n",
    "spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adef6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=======================================================>(99 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "|index|       cleaned_title|        cleaned_text|label|num_special_chars|num_determinants|num_capital_letters|num_short_sentences|num_long_sentences|       gunning_fog|              smog|               ari|            polarity|title_similarity|       subjectivity|num_syllables|num_words|       rate_adj_adv|words_per_sentence|num_articles|num_verbs|num_sentences|num_adjectives|num_adverbs|\n",
      "+-----+--------------------+--------------------+-----+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "|10018|CLINTON PAL AND F...|The Democrat s wa...|    1|               29|              15|                 53|                  3|                 5| 12.07313432835821|12.311054993355175| 9.352475247524755| 0.07575757575757576|             0.0| 0.4487373737373738|          319|      191|0.12041884816753927|15.916666666666666|          15|       27|           12|            14|          9|\n",
      "|50332|Elected Official ...|John Bennet, a Re...|    1|               14|              13|                 23|                  1|                 3|12.963636363636363| 12.38480682065935|10.833863636363638|-0.01716666666666...|             0.0| 0.5556666666666666|          217|      128|          0.1328125|              16.0|          13|       23|            8|            12|          5|\n",
      "|60141|SHOCKING MIGRANT ...|The streets of Pa...|    1|               30|              21|                 68|                  3|                 9|15.118637653736995|14.244340213328723|13.373595080416273|  0.1087912087912088|             0.0|0.31254578754578755|          487|      290|0.11379310344827587|20.714285714285715|          21|       62|           14|            26|          7|\n",
      "|36751|MSNBC: \"The Trump...|Persuasion is so ...|    1|               27|              14|                 28|                  4|                 3| 13.15023923444976|13.023866798666859| 11.52985645933014| 0.04250000000000001|             0.0|              0.515|          326|      207| 0.0966183574879227|             17.25|          14|       47|           12|            10|         10|\n",
      "|34457|September New Hom...|September New Hom...|    1|               14|               3|                 36|                  3|                 2|12.102439024390245|12.161744961471694|14.437804878048787| 0.10606060606060606|             0.0| 0.4424242424242424|          138|       79|0.12658227848101267|             19.75|           3|        7|            4|             6|          4|\n",
      "+-----+--------------------+--------------------+-----+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, rand, row_number\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.appName(\"WELFake Features\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "feature_schema = StructType([\n",
    "    StructField(\"num_special_chars\", IntegerType()),\n",
    "    StructField(\"num_determinants\", IntegerType()),\n",
    "    StructField(\"num_capital_letters\", IntegerType()),\n",
    "    StructField(\"num_short_sentences\", IntegerType()),\n",
    "    StructField(\"num_long_sentences\", IntegerType()),\n",
    "    StructField(\"gunning_fog\", DoubleType()),\n",
    "    StructField(\"smog\", DoubleType()),\n",
    "    StructField(\"ari\", DoubleType()),\n",
    "    StructField(\"polarity\", DoubleType()),\n",
    "    StructField(\"title_similarity\", DoubleType()),\n",
    "    StructField(\"subjectivity\", DoubleType()),\n",
    "    StructField(\"num_syllables\", IntegerType()),\n",
    "    StructField(\"num_words\", IntegerType()),\n",
    "    StructField(\"rate_adj_adv\", DoubleType()),\n",
    "    StructField(\"words_per_sentence\", DoubleType()),\n",
    "    StructField(\"num_articles\", IntegerType()),\n",
    "    StructField(\"num_verbs\", IntegerType()),\n",
    "    StructField(\"num_sentences\", IntegerType()),\n",
    "    StructField(\"num_adjectives\", IntegerType()),\n",
    "    StructField(\"num_adverbs\", IntegerType())\n",
    "])\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        pos_tags = pos_tag(words)\n",
    "\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
    "        num_determinants = sum(1 for w in words if w.lower() in ['the', 'a', 'an'])\n",
    "        num_capital_letters = sum(1 for c in text if c.isupper())\n",
    "        num_short_sent = sum(1 for s in sentences if len(s.split()) < 10)\n",
    "        num_long_sent = sum(1 for s in sentences if len(s.split()) > 20)\n",
    "\n",
    "        gunning_fog = textstat.gunning_fog(text)\n",
    "        smog = textstat.smog_index(text)\n",
    "        ari = textstat.automated_readability_index(text)\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        title_similarity = 0.0\n",
    "\n",
    "        num_syllables = textstat.syllable_count(text)\n",
    "        num_words = len(words)\n",
    "        num_sentences = len([s for s in sentences if s.strip()])\n",
    "        num_adjectives = sum(1 for _, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS'])\n",
    "        num_adverbs = sum(1 for _, tag in pos_tags if tag in ['RB', 'RBR', 'RBS'])\n",
    "        num_verbs = sum(1 for _, tag in pos_tags if tag.startswith('VB'))\n",
    "        num_articles = sum(1 for w in words if w.lower() in ['a', 'an', 'the'])\n",
    "\n",
    "        rate_adj_adv = (num_adjectives + num_adverbs) / num_words if num_words > 0 else 0\n",
    "        words_per_sent = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "        return (\n",
    "            num_special_chars, num_determinants, num_capital_letters, num_short_sent, num_long_sent,\n",
    "            gunning_fog, smog, ari,\n",
    "            polarity, title_similarity, subjectivity,\n",
    "            num_syllables, num_words, rate_adj_adv, words_per_sent,\n",
    "            num_articles, num_verbs, num_sentences, num_adjectives, num_adverbs\n",
    "        )\n",
    "    except:\n",
    "        return (None,) * 20\n",
    "\n",
    "# Register UDF\n",
    "extract_features_udf = udf(extract_features, feature_schema)\n",
    "\n",
    "# Explicit schema for your dataset\n",
    "schema = StructType([\n",
    "    StructField(\"index\", IntegerType(), True),\n",
    "    StructField(\"cleaned_title\", StringType(), True),\n",
    "    StructField(\"cleaned_text\", StringType(), True),\n",
    "    StructField(\"label\", IntegerType(), True),   # force label as integer\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "spark_df = spark.read.csv(\n",
    "    \"cleaned_welfake.csv\",\n",
    "    header=True,\n",
    "    schema=schema,\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    multiLine=True  # needed since your text column contains line breaks\n",
    ")\n",
    "\n",
    "# --- Stratified sampling with Window (exact N per label) ---\n",
    "n = 100  # number of rows per class\n",
    "w = Window.partitionBy(\"label\").orderBy(rand(seed=42))\n",
    "df_ranked = spark_df.withColumn(\"row_num\", row_number().over(w))\n",
    "df_sampled = df_ranked.filter(col(\"row_num\") <= n).drop(\"row_num\")\n",
    "\n",
    "# Apply feature extraction\n",
    "df_with_features = df_sampled.withColumn(\"features\", extract_features_udf(\"cleaned_text\"))\n",
    "\n",
    "# Flatten struct\n",
    "for col_name in feature_schema.fieldNames():\n",
    "    df_with_features = df_with_features.withColumn(col_name, df_with_features[\"features\"][col_name])\n",
    "\n",
    "df_with_features = df_with_features.drop(\"features\")\n",
    "\n",
    "df_with_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b572913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e9cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_features = df_with_features.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14019b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/18 17:48:20 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "25/08/18 17:48:20 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "Exception in thread \"RemoteBlock-temp-file-clean-thread\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.storage.BlockManager$RemoteBlockDownloadFileManager$$Lambda$836/0x000000030084d840.get$Lambda(Unknown Source)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n",
      "\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000000300062840.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.storage.BlockManager$RemoteBlockDownloadFileManager.org$apache$spark$storage$BlockManager$RemoteBlockDownloadFileManager$$keepCleaning(BlockManager.scala:1940)\n",
      "\tat org.apache.spark.storage.BlockManager$RemoteBlockDownloadFileManager$$anon$2.run(BlockManager.scala:1906)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1127.count.\n: java.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.HashSet$HashTrieSet.updated0(HashSet.scala:557)\n\tat scala.collection.immutable.HashSet.$plus(HashSet.scala:84)\n\tat scala.collection.immutable.Set$Set4.$plus(Set.scala:198)\n\tat scala.collection.immutable.Set$Set4.$plus(Set.scala:192)\n\tat scala.collection.mutable.SetBuilder.$plus$eq(SetBuilder.scala:28)\n\tat scala.collection.mutable.SetBuilder.$plus$eq(SetBuilder.scala:24)\n\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n\tat scala.collection.generic.Growable$$Lambda$10/0x0000000300115840.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.SetBuilder.$plus$plus$eq(SetBuilder.scala:24)\n\tat scala.collection.TraversableLike.to(TraversableLike.scala:678)\n\tat scala.collection.TraversableLike.to$(TraversableLike.scala:675)\n\tat scala.collection.AbstractTraversable.to(Traversable.scala:108)\n\tat scala.collection.TraversableOnce.toSet(TraversableOnce.scala:309)\n\tat scala.collection.TraversableOnce.toSet$(TraversableOnce.scala:309)\n\tat scala.collection.AbstractTraversable.toSet(Traversable.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.containsChild$lzycompute(TreeNode.scala:115)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.containsChild(TreeNode.scala:115)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChild$1(TreeNode.scala:263)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$withNewChildren$4(TreeNode.scala:276)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$Lambda$1549/0x0000000300cbd040.apply(Unknown Source)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike$$Lambda$60/0x00000003001e3040.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 119\u001b[0m\n\u001b[1;32m    114\u001b[0m final_preds \u001b[38;5;241m=\u001b[39m final_preds\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_vote\u001b[39m\u001b[38;5;124m\"\u001b[39m, final_vote_udf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage1_vote\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_cv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_tfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# --------------------------------------\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# --------------------------------------\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_vote\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m final_preds\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:585\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;241m1.3\u001b[39m)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m    >>> df.count()\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/sql/utils.py:131\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    133\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1127.count.\n: java.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.HashSet$HashTrieSet.updated0(HashSet.scala:557)\n\tat scala.collection.immutable.HashSet.$plus(HashSet.scala:84)\n\tat scala.collection.immutable.Set$Set4.$plus(Set.scala:198)\n\tat scala.collection.immutable.Set$Set4.$plus(Set.scala:192)\n\tat scala.collection.mutable.SetBuilder.$plus$eq(SetBuilder.scala:28)\n\tat scala.collection.mutable.SetBuilder.$plus$eq(SetBuilder.scala:24)\n\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n\tat scala.collection.generic.Growable$$Lambda$10/0x0000000300115840.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.SetBuilder.$plus$plus$eq(SetBuilder.scala:24)\n\tat scala.collection.TraversableLike.to(TraversableLike.scala:678)\n\tat scala.collection.TraversableLike.to$(TraversableLike.scala:675)\n\tat scala.collection.AbstractTraversable.to(Traversable.scala:108)\n\tat scala.collection.TraversableOnce.toSet(TraversableOnce.scala:309)\n\tat scala.collection.TraversableOnce.toSet$(TraversableOnce.scala:309)\n\tat scala.collection.AbstractTraversable.toSet(Traversable.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.containsChild$lzycompute(TreeNode.scala:115)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.containsChild(TreeNode.scala:115)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChild$1(TreeNode.scala:263)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$withNewChildren$4(TreeNode.scala:276)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$Lambda$1549/0x0000000300cbd040.apply(Unknown Source)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike$$Lambda$60/0x00000003001e3040.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/18 20:21:59 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1037087 ms exceeds timeout 120000 ms\n",
      "25/08/18 20:21:59 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from functools import reduce\n",
    "\n",
    "# --------------------------------------\n",
    "# Spark session\n",
    "# --------------------------------------\n",
    "# spark = SparkSession.builder.appName(\"WELFake-PySpark\").getOrCreate()\n",
    "\n",
    "# --------------------------------------\n",
    "# Define LFS feature groups (same as sklearn version)\n",
    "# --------------------------------------\n",
    "LFS1 = ['num_special_chars','num_determinants','num_capital_letters',\n",
    "        'gunning_fog','polarity','num_syllables']\n",
    "LFS2 = ['num_short_sentences','smog','title_similarity',\n",
    "        'subjectivity','num_words','rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences','ari','num_articles',\n",
    "        'num_verbs','num_sentences','words_per_sentence']\n",
    "\n",
    "# --------------------------------------\n",
    "# Tokenizer + CV + TF-IDF\n",
    "# --------------------------------------\n",
    "tokenizer = RegexTokenizer(inputCol=\"cleaned_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"cv_features\", vocabSize=5000, minDF=2)\n",
    "idf = IDF(inputCol=\"cv_features\", outputCol=\"tfidf_features\")\n",
    "\n",
    "# Assemble CV+LFS features\n",
    "vec1 = VectorAssembler(inputCols=LFS1 + [\"cv_features\"], outputCol=\"features_lfs1\")\n",
    "vec2 = VectorAssembler(inputCols=LFS2 + [\"cv_features\"], outputCol=\"features_lfs2\")\n",
    "vec3 = VectorAssembler(inputCols=LFS3 + [\"cv_features\"], outputCol=\"features_lfs3\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Train/test split\n",
    "# --------------------------------------\n",
    "# # ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "# if \"pandas\" in str(type(df_sampled)):\n",
    "#     try:\n",
    "#         spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "#     except Exception:\n",
    "#         # fallback for Pandas >= 2.0\n",
    "#         spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "# else:\n",
    "#     spark_df = df_sampled\n",
    "\n",
    "# # ✅ Cast label to integer (required for MLlib)\n",
    "# spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "df_with_features = df_with_features.na.drop()\n",
    "train_df, test_df = df_with_features.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 1: feature extraction (tokenizer + cv + idf + assemblers)\n",
    "# --------------------------------------\n",
    "base_pipeline = Pipeline(stages=[tokenizer, cv, idf, vec1, vec2, vec3])\n",
    "base_model = base_pipeline.fit(train_df)\n",
    "train_feats = base_model.transform(train_df)\n",
    "test_feats  = base_model.transform(test_df)\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 1: train three SVMs on LFS1/2/3\n",
    "# --------------------------------------\n",
    "svm1 = LinearSVC(featuresCol=\"features_lfs1\", labelCol=\"label\", predictionCol=\"pred1\", rawPredictionCol=\"raw1\")\n",
    "svm2 = LinearSVC(featuresCol=\"features_lfs2\", labelCol=\"label\", predictionCol=\"pred2\", rawPredictionCol=\"raw2\")\n",
    "svm3 = LinearSVC(featuresCol=\"features_lfs3\", labelCol=\"label\", predictionCol=\"pred3\", rawPredictionCol=\"raw3\")\n",
    "\n",
    "svm1_model = svm1.fit(train_feats)\n",
    "svm2_model = svm2.fit(train_feats)\n",
    "svm3_model = svm3.fit(train_feats)\n",
    "\n",
    "# Predictions from each SVM\n",
    "preds1 = svm1_model.transform(test_feats).select(\"index\",\"pred1\")\n",
    "preds2 = svm2_model.transform(test_feats).select(\"index\",\"pred2\")\n",
    "preds3 = svm3_model.transform(test_feats).select(\"index\",\"pred3\")\n",
    "\n",
    "# Join predictions + label\n",
    "preds_all = reduce(\n",
    "    lambda l,r: l.join(r, on=\"index\"),\n",
    "    [test_feats.select(\"index\",\"label\"), preds1, preds2, preds3]\n",
    ")\n",
    "\n",
    "# Majority vote UDF\n",
    "vote_udf = F.udf(lambda p1,p2,p3: int(round((p1+p2+p3)/3.0)), IntegerType())\n",
    "preds_all = preds_all.withColumn(\"stage1_vote\", vote_udf(\"pred1\",\"pred2\",\"pred3\"))\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 2: CV-only and TF-IDF-only models\n",
    "# --------------------------------------\n",
    "vec_cv = VectorAssembler(inputCols=[\"cv_features\"], outputCol=\"cv_final\")\n",
    "vec_tfidf = VectorAssembler(inputCols=[\"tfidf_features\"], outputCol=\"tfidf_final\")\n",
    "\n",
    "train_feats2 = vec_cv.transform(train_feats)\n",
    "train_feats2 = vec_tfidf.transform(train_feats2)\n",
    "test_feats2  = vec_cv.transform(test_feats)\n",
    "test_feats2  = vec_tfidf.transform(test_feats2)\n",
    "\n",
    "svm_cv = LinearSVC(featuresCol=\"cv_final\", labelCol=\"label\", predictionCol=\"pred_cv\", rawPredictionCol=\"rawCV\")\n",
    "svm_tfidf = LinearSVC(featuresCol=\"tfidf_final\", labelCol=\"label\", predictionCol=\"pred_tfidf\", rawPredictionCol=\"rawTFIDF\")\n",
    "\n",
    "svm_cv_model = svm_cv.fit(train_feats2)\n",
    "svm_tfidf_model = svm_tfidf.fit(train_feats2)\n",
    "\n",
    "preds_cv = svm_cv_model.transform(test_feats2).select(\"index\",\"pred_cv\")\n",
    "preds_tfidf = svm_tfidf_model.transform(test_feats2).select(\"index\",\"pred_tfidf\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Final voting: combine Stage1 vote + CV + TF-IDF\n",
    "# --------------------------------------\n",
    "final_preds = preds_all.join(preds_cv, on=\"index\").join(preds_tfidf, on=\"index\")\n",
    "\n",
    "final_vote_udf = F.udf(lambda p1,p2,p3: int(round((p1+p2+p3)/3.0)), IntegerType())\n",
    "final_preds = final_preds.withColumn(\"final_vote\", final_vote_udf(\"stage1_vote\",\"pred_cv\",\"pred_tfidf\"))\n",
    "\n",
    "# --------------------------------------\n",
    "# Evaluate accuracy\n",
    "# --------------------------------------\n",
    "accuracy = final_preds.filter(F.col(\"final_vote\") == F.col(\"label\")).count() / final_preds.count()\n",
    "print(\"Final Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29738a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/18 17:43:18 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|   70|\n",
      "|    0|   70|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|   30|\n",
      "|    0|   30|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, rand, row_number\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "# Randomly order within each class\n",
    "w = Window.partitionBy(\"label\").orderBy(F.rand(seed=42))\n",
    "df_ranked = df_with_features.withColumn(\"row_num\", F.row_number().over(w))\n",
    "\n",
    "# Count per label\n",
    "label_counts = df_with_features.groupBy(\"label\").count().collect()\n",
    "label_counts = {row[\"label\"]: row[\"count\"] for row in label_counts}\n",
    "\n",
    "# Assign rows to train/test based on ratio\n",
    "df_split = df_ranked.withColumn(\n",
    "    \"set\",\n",
    "    F.when(\n",
    "        F.col(\"row_num\") <= (F.lit(train_ratio) * F.lit(label_counts[0])).cast(\"int\"),\n",
    "        \"train\"\n",
    "    ).when(\n",
    "        (F.col(\"label\") == 1) & (F.col(\"row_num\") <= (F.lit(train_ratio) * F.lit(label_counts[1])).cast(\"int\")),\n",
    "        \"train\"\n",
    "    ).otherwise(\"test\")\n",
    ")\n",
    "\n",
    "train_df = df_split.filter(F.col(\"set\") == \"train\").drop(\"row_num\", \"set\")\n",
    "test_df = df_split.filter(F.col(\"set\") == \"test\").drop(\"row_num\", \"set\")\n",
    "\n",
    "# Verify stratification\n",
    "train_df.groupBy(\"label\").count().show()\n",
    "test_df.groupBy(\"label\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welfake-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
