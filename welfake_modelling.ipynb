{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04300ecf",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d02bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bachtiarherdianto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bachtiarherdianto/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import textstat\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627bb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        pos_tags = pos_tag(words)\n",
    "        \n",
    "        # Writing pattern\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
    "        num_determinants = sum(1 for w in words if w.lower() in ['the', 'a', 'an'])\n",
    "        num_capital_letters = sum(1 for c in text if c.isupper())\n",
    "        num_short_sentences = sum(1 for s in sentences if len(s.split()) < 10)\n",
    "        num_long_sentences = sum(1 for s in sentences if len(s.split()) > 20)\n",
    "\n",
    "        # Readability indices\n",
    "        gunning_fog = textstat.gunning_fog(text)\n",
    "        smog = textstat.smog_index(text)\n",
    "        ari = textstat.automated_readability_index(text)\n",
    "\n",
    "        # Psycholinguistics\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        title_similarity = 0  # Optional, you can compute this with cosine or Jaccard if you have 'title'\n",
    "\n",
    "        # Quantity\n",
    "        num_syllables = textstat.syllable_count(text)\n",
    "        num_words = len(words)\n",
    "        num_sentences = len([s for s in sentences if s.strip()])\n",
    "        num_adjectives = sum(1 for _, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS'])\n",
    "        num_adverbs = sum(1 for _, tag in pos_tags if tag in ['RB', 'RBR', 'RBS'])\n",
    "        num_verbs = sum(1 for _, tag in pos_tags if tag.startswith('VB'))\n",
    "        num_articles = sum(1 for w in words if w.lower() in ['a', 'an', 'the'])\n",
    "\n",
    "        rate_adj_adv = (num_adjectives + num_adverbs) / num_words if num_words > 0 else 0\n",
    "        words_per_sentence = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "        return pd.Series([\n",
    "            num_special_chars, num_determinants, num_capital_letters, num_short_sentences, num_long_sentences,\n",
    "            gunning_fog, smog, ari,\n",
    "            polarity, title_similarity, subjectivity,\n",
    "            num_syllables, num_words, rate_adj_adv, words_per_sentence,\n",
    "            num_articles, num_verbs, num_sentences, num_adjectives, num_adverbs\n",
    "        ])\n",
    "    except:\n",
    "        return pd.Series([None]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9aa7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        pos_tags = pos_tag(words)\n",
    "        \n",
    "        # Writing pattern\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
    "        num_determinants = sum(1 for w in words if w.lower() in ['the', 'a', 'an'])\n",
    "        num_capital_letters = sum(1 for c in text if c.isupper())\n",
    "        num_short_sentences = sum(1 for s in sentences if len(s.split()) < 10)\n",
    "        num_long_sentences = sum(1 for s in sentences if len(s.split()) > 20)\n",
    "\n",
    "        # Readability indices\n",
    "        gunning_fog = textstat.gunning_fog(text)\n",
    "        smog = textstat.smog_index(text)\n",
    "        ari = textstat.automated_readability_index(text)\n",
    "\n",
    "        # Psycholinguistics\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        title_similarity = 0  # Optional, you can compute this with cosine or Jaccard if you have 'title'\n",
    "\n",
    "        # Quantity\n",
    "        num_syllables = textstat.syllable_count(text)\n",
    "        num_words = len(words)\n",
    "        num_sentences = len([s for s in sentences if s.strip()])\n",
    "        num_adjectives = sum(1 for _, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS'])\n",
    "        num_adverbs = sum(1 for _, tag in pos_tags if tag in ['RB', 'RBR', 'RBS'])\n",
    "        num_verbs = sum(1 for _, tag in pos_tags if tag.startswith('VB'))\n",
    "        num_articles = sum(1 for w in words if w.lower() in ['a', 'an', 'the'])\n",
    "\n",
    "        rate_adj_adv = (num_adjectives + num_adverbs) / num_words if num_words > 0 else 0\n",
    "        words_per_sentence = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "        return pd.Series([\n",
    "            num_special_chars, num_determinants, num_capital_letters, num_short_sentences, num_long_sentences,\n",
    "            gunning_fog, smog, ari,\n",
    "            polarity, title_similarity, subjectivity,\n",
    "            num_syllables, num_words, rate_adj_adv, words_per_sentence,\n",
    "            num_articles, num_verbs, num_sentences, num_adjectives, num_adverbs\n",
    "        ])\n",
    "    except:\n",
    "        return pd.Series([None]*20)\n",
    "    \n",
    "df = pd.read_csv('cleaned_welfake.csv')\n",
    "\n",
    "\n",
    "# Sample 2 rows per class\n",
    "df_sampled = df.groupby('label', group_keys=False).sample(n=1000, random_state=42)\n",
    "df_sampled.head()\n",
    "\n",
    "# Assuming your dataframe is called df and has a 'text' column\n",
    "feature_columns = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "df_sampled[feature_columns] = df_sampled['cleaned_text'].apply(extract_features)\n",
    "\n",
    "df_sampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63e6a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21354</th>\n",
       "      <td>17322</td>\n",
       "      <td>Trump's choice for U.S. attorney general says ...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President-elect Do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>21871</td>\n",
       "      <td>Alison Wright, Exiled From 'The Americans' (Pe...</td>\n",
       "      <td>It took Alison Wright 34 years to land her fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>32704</td>\n",
       "      <td>Kurdistan supervisors begin counting votes in ...</td>\n",
       "      <td>ERBIL, Iraq (Reuters) - Voting stations set up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24177</th>\n",
       "      <td>35894</td>\n",
       "      <td>New Saudi king ascends to the throne as terror...</td>\n",
       "      <td>At 3 a.m. on a cold desert night earlier this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>24368</td>\n",
       "      <td>May shook on gentlemen's agreement on Brexit d...</td>\n",
       "      <td>BRUSSELS (Reuters) - An interim Brexit deal st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                      cleaned_title  \\\n",
       "21354  17322  Trump's choice for U.S. attorney general says ...   \n",
       "25012  21871  Alison Wright, Exiled From 'The Americans' (Pe...   \n",
       "9901   32704  Kurdistan supervisors begin counting votes in ...   \n",
       "24177  35894  New Saudi king ascends to the throne as terror...   \n",
       "37552  24368  May shook on gentlemen's agreement on Brexit d...   \n",
       "\n",
       "                                            cleaned_text  label  \n",
       "21354  WASHINGTON (Reuters) - U.S. President-elect Do...      0  \n",
       "25012  It took Alison Wright 34 years to land her fir...      0  \n",
       "9901   ERBIL, Iraq (Reuters) - Voting stations set up...      0  \n",
       "24177  At 3 a.m. on a cold desert night earlier this ...      0  \n",
       "37552  BRUSSELS (Reuters) - An interim Brexit deal st...      0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_welfake.csv')\n",
    "\n",
    "# # Sample 50% from each class\n",
    "# df_sampled = df.groupby('label', group_keys=False).sample(frac=0.5, random_state=42)\n",
    "\n",
    "# Sample 2 rows per class\n",
    "df_sampled = df.groupby('label', group_keys=False).sample(n=1000, random_state=42)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9441ce1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'cleaned_title', 'cleaned_text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28da488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    100\n",
      "1    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_sampled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f95a2582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 21354 to 15142\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   index                2000 non-null   int64  \n",
      " 1   cleaned_title        2000 non-null   object \n",
      " 2   cleaned_text         2000 non-null   object \n",
      " 3   label                2000 non-null   int64  \n",
      " 4   num_special_chars    2000 non-null   float64\n",
      " 5   num_determinants     2000 non-null   float64\n",
      " 6   num_capital_letters  2000 non-null   float64\n",
      " 7   num_short_sentences  2000 non-null   float64\n",
      " 8   num_long_sentences   2000 non-null   float64\n",
      " 9   gunning_fog          2000 non-null   float64\n",
      " 10  smog                 2000 non-null   float64\n",
      " 11  ari                  2000 non-null   float64\n",
      " 12  polarity             2000 non-null   float64\n",
      " 13  title_similarity     2000 non-null   float64\n",
      " 14  subjectivity         2000 non-null   float64\n",
      " 15  num_syllables        2000 non-null   float64\n",
      " 16  num_words            2000 non-null   float64\n",
      " 17  rate_adj_adv         2000 non-null   float64\n",
      " 18  words_per_sentence   2000 non-null   float64\n",
      " 19  num_articles         2000 non-null   float64\n",
      " 20  num_verbs            2000 non-null   float64\n",
      " 21  num_sentences        2000 non-null   float64\n",
      " 22  num_adjectives       2000 non-null   float64\n",
      " 23  num_adverbs          2000 non-null   float64\n",
      "dtypes: float64(20), int64(2), object(2)\n",
      "memory usage: 390.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called df and has a 'text' column\n",
    "feature_columns = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# # Apply feature extraction and add prefix to the resulting columns\n",
    "# df_sampled[text_feature_cols := ['text_' + col for col in feature_columns]] = (\n",
    "#     df_sampled['cleaned_text'].apply(extract_features)\n",
    "# )\n",
    "\n",
    "# # Apply feature extraction and add prefix to the resulting columns\n",
    "# df_sampled[title_feature_cols := ['title_' + col for col in feature_columns]] = (\n",
    "#     df_sampled['cleaned_title'].apply(extract_features)\n",
    "# )\n",
    "\n",
    "df_sampled[feature_columns] = df_sampled['cleaned_text'].apply(extract_features)\n",
    "\n",
    "df_sampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1c8b4",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdada038",
   "metadata": {},
   "source": [
    "#### Pandas Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ca3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bccfef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "# text_feature_cols + title_feature_cols\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "X = df_sampled[feature_cols]\n",
    "y = df_sampled['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8ef76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "1                  SVM     0.825\n",
      "9  Logistic Regression     0.825\n",
      "4              Bagging     0.725\n",
      "6        Random Forest     0.725\n",
      "8          Extra Trees     0.725\n",
      "0                  KNN     0.675\n",
      "5             AdaBoost     0.675\n",
      "2          Naive Bayes     0.650\n",
      "3        Decision Tree     0.650\n",
      "7    Gradient Boosting     0.650\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "    # print(f\"✅ {name} Accuracy: {acc:.4f}\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy_df = pd.DataFrame([\n",
    "    {'Model': name, 'Accuracy': result['accuracy']}\n",
    "    for name, result in results.items()\n",
    "])\n",
    "print(accuracy_df.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f1d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "feature_cols = [\n",
    "# text_feature_cols + title_feature_cols\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7356f845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8983333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf0da7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Example: Define your LFS feature groups (replace with your actual 20 features split into 3 sets)\n",
    "LFS1 = ['num_special_chars', 'num_determinants', 'num_capital_letters', \n",
    "        'gunning_fog', 'polarity', 'num_syllables']\n",
    "LFS2 = ['num_short_sentences', 'smog', 'title_similarity',\n",
    "        'subjectivity', 'num_words', 'rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences', 'ari', 'num_articles', \n",
    "        'num_verbs', 'num_sentences', 'words_per_sentence']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sampled, df_sampled['label'], test_size=0.3, random_state=42, stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "# Function to apply CV + LFS\n",
    "def cv_over_lfs(X_train, X_test, lfs_cols):\n",
    "    \"\"\"Apply Count Vectorizer to text + concatenate LFS numeric features.\"\"\"\n",
    "    cv = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X_train_cv = cv.fit_transform(X_train['cleaned_text'])\n",
    "    X_test_cv = cv.transform(X_test['cleaned_text'])\n",
    "\n",
    "    # Scale LFS numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_lfs = scaler.fit_transform(X_train[lfs_cols])\n",
    "    X_test_lfs = scaler.transform(X_test[lfs_cols])\n",
    "\n",
    "    # Combine sparse CV with dense LFS\n",
    "    X_train_combined = hstack([X_train_cv, X_train_lfs])\n",
    "    X_test_combined = hstack([X_test_cv, X_test_lfs])\n",
    "    \n",
    "    return X_train_combined, X_test_combined\n",
    "\n",
    "# Generate embedded sets\n",
    "Xtr_LFS1, Xte_LFS1 = cv_over_lfs(X_train, X_test, LFS1)\n",
    "Xtr_LFS2, Xte_LFS2 = cv_over_lfs(X_train, X_test, LFS2)\n",
    "Xtr_LFS3, Xte_LFS3 = cv_over_lfs(X_train, X_test, LFS3)\n",
    "\n",
    "# Define base model (SVM as per WELFake best performer)\n",
    "svm1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm2 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm3 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Fit each SVM\n",
    "svm1.fit(Xtr_LFS1, y_train)\n",
    "svm2.fit(Xtr_LFS2, y_train)\n",
    "svm3.fit(Xtr_LFS3, y_train)\n",
    "\n",
    "# Stage 1 voting: combine predictions from LFS1, LFS2, LFS3\n",
    "stage1_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm1', svm1),\n",
    "        ('svm2', svm2),\n",
    "        ('svm3', svm3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "stage1_vote.fit(\n",
    "    hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]),  # Stack features for VotingClassifier fit\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Stage 1 predictions\n",
    "P6_train = stage1_vote.predict(hstack([Xtr_LFS1, Xtr_LFS2, Xtr_LFS3]))\n",
    "P6_test = stage1_vote.predict(hstack([Xte_LFS1, Xte_LFS2, Xte_LFS3]))\n",
    "\n",
    "# ----- Stage 2: Combine P6 with CV-only and TF-IDF-only -----\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CV-only on full text\n",
    "cv_full = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_cv_full = cv_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_cv_full = cv_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# TF-IDF-only on full text\n",
    "tfidf_full = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "Xtr_tfidf_full = tfidf_full.fit_transform(X_train['cleaned_text'])\n",
    "Xte_tfidf_full = tfidf_full.transform(X_test['cleaned_text'])\n",
    "\n",
    "# Final stage voting: P6, CV, TF-IDF\n",
    "final_vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('cv_svm', SVC(kernel='linear', probability=True).fit(Xtr_cv_full, y_train)),\n",
    "        ('tfidf_svm', SVC(kernel='linear', probability=True).fit(Xtr_tfidf_full, y_train)),\n",
    "        ('lfs_vote', stage1_vote)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "final_vote.fit(Xtr_cv_full, y_train)  # Fit on one set, predictions from others are internal\n",
    "\n",
    "# Final prediction\n",
    "final_preds = final_vote.predict(Xte_cv_full)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b309f5",
   "metadata": {},
   "source": [
    "#### Pyspark Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a272b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/bachtiarherdianto/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "25/08/18 16:36:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/18 16:36:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session (only once)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fake News Detection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dfdd134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Model              |Accuracy          |Precision         |Recall            |F1                |AUC                |\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Random Forest      |0.6585365853658537|0.6757973733583489|0.6585365853658537|0.652350653941322 |0.7714285714285715 |\n",
      "|Decision Tree      |0.6097560975609756|0.6333422674886089|0.6097560975609756|0.5963653754184601|0.48571428571428565|\n",
      "|Logistic Regression|0.6097560975609756|0.6228893058161351|0.6097560975609756|0.6026864616472252|0.7119047619047618 |\n",
      "|Gradient Boosting  |0.5853658536585366|0.6002710027100271|0.5853658536585366|0.5747794499221588|0.65               |\n",
      "|Naive Bayes        |0.5609756097560976|0.561219512195122 |0.5609756097560976|0.5556733828207847|0.519047619047619  |\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, DecisionTreeClassifier, RandomForestClassifier,\n",
    "    GBTClassifier, NaiveBayes\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Define features\n",
    "feature_cols = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "# Assemble features into vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "from pyspark.sql import Row\n",
    "spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Models available in Spark MLlib\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100),\n",
    "    \"Gradient Boosting\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"gaussian\")\n",
    "}\n",
    "\n",
    "# Evaluators\n",
    "bin_eval = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, clf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    preds = model.transform(test_df)\n",
    "\n",
    "    acc = multi_eval.setMetricName(\"accuracy\").evaluate(preds)\n",
    "    f1 = multi_eval.setMetricName(\"f1\").evaluate(preds)\n",
    "    precision = multi_eval.setMetricName(\"weightedPrecision\").evaluate(preds)\n",
    "    recall = multi_eval.setMetricName(\"weightedRecall\").evaluate(preds)\n",
    "    auc = bin_eval.evaluate(preds)\n",
    "\n",
    "    results.append((name, acc, precision, recall, f1, auc))\n",
    "\n",
    "# Convert results to Spark DataFrame\n",
    "results_df = spark.createDataFrame(results, [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
    "results_df.orderBy(\"Accuracy\", ascending=False).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93e947ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.652351</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.622889</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.602686</td>\n",
       "      <td>0.711905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.633342</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.596365</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.600271</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.574779</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.561220</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.555673</td>\n",
       "      <td>0.519048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall        F1       AUC\n",
       "2        Random Forest  0.658537   0.675797  0.658537  0.652351  0.771429\n",
       "0  Logistic Regression  0.609756   0.622889  0.609756  0.602686  0.711905\n",
       "1        Decision Tree  0.609756   0.633342  0.609756  0.596365  0.485714\n",
       "3    Gradient Boosting  0.585366   0.600271  0.585366  0.574779  0.650000\n",
       "4          Naive Bayes  0.560976   0.561220  0.560976  0.555673  0.519048"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"]).sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6d42f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Model                  |Accuracy          |Precision         |Recall            |F1                |AUC                |\n",
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|Linear SVM             |0.7073170731707317|0.7287054409005629|0.7073170731707317|0.702014846235419 |0.7523809523809524 |\n",
      "|Random Forest          |0.6585365853658537|0.6757973733583489|0.6585365853658537|0.652350653941322 |0.7714285714285715 |\n",
      "|Decision Tree          |0.6097560975609756|0.6333422674886089|0.6097560975609756|0.5963653754184601|0.48571428571428565|\n",
      "|Logistic Regression    |0.6097560975609756|0.6228893058161351|0.6097560975609756|0.6026864616472252|0.7119047619047618 |\n",
      "|Gradient Boosting (GBT)|0.5853658536585366|0.6002710027100271|0.5853658536585366|0.5747794499221588|0.65               |\n",
      "|Naive Bayes            |0.5609756097560976|0.561219512195122 |0.5609756097560976|0.5556733828207847|0.519047619047619  |\n",
      "+-----------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, DecisionTreeClassifier, RandomForestClassifier,\n",
    "    GBTClassifier, NaiveBayes, LinearSVC\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# ✅ Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"Fake News Detection PySpark4\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "if \"pandas\" in str(type(df_sampled)):\n",
    "    try:\n",
    "        spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "    except Exception:\n",
    "        # fallback for Pandas >= 2.0\n",
    "        spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "else:\n",
    "    spark_df = df_sampled\n",
    "\n",
    "# ✅ Cast label to integer (required for MLlib)\n",
    "spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "# ✅ Features\n",
    "feature_cols = [\n",
    "    'num_special_chars', 'num_determinants', 'num_capital_letters', 'num_short_sentences', 'num_long_sentences',\n",
    "    'gunning_fog', 'smog', 'ari',\n",
    "    'polarity', 'title_similarity', 'subjectivity',\n",
    "    'num_syllables', 'num_words', 'rate_adj_adv', 'words_per_sentence',\n",
    "    'num_articles', 'num_verbs', 'num_sentences', 'num_adjectives', 'num_adverbs'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_vec\")\n",
    "scaler = StandardScaler(inputCol=\"features_vec\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "# ✅ Split train/test\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# ✅ Models (all supported in PySpark 4.0)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100),\n",
    "    \"Gradient Boosting (GBT)\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=100),\n",
    "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"gaussian\"),\n",
    "    \"Linear SVM\": LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.01)\n",
    "}\n",
    "\n",
    "# ✅ Evaluators\n",
    "bin_eval = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, clf])\n",
    "    model = pipeline.fit(train_df)\n",
    "    preds = model.transform(test_df)\n",
    "\n",
    "    acc = multi_eval.setMetricName(\"accuracy\").evaluate(preds)\n",
    "    f1 = multi_eval.setMetricName(\"f1\").evaluate(preds)\n",
    "    precision = multi_eval.setMetricName(\"weightedPrecision\").evaluate(preds)\n",
    "    recall = multi_eval.setMetricName(\"weightedRecall\").evaluate(preds)\n",
    "    auc = bin_eval.evaluate(preds)\n",
    "\n",
    "    results.append((name, acc, precision, recall, f1, auc))\n",
    "\n",
    "# ✅ Show Results\n",
    "results_df = spark.createDataFrame(results, [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
    "results_df.orderBy(\"Accuracy\", ascending=False).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "if \"pandas\" in str(type(df_sampled)):\n",
    "    try:\n",
    "        spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "    except Exception:\n",
    "        # fallback for Pandas >= 2.0\n",
    "        spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "else:\n",
    "    spark_df = df_sampled\n",
    "\n",
    "# ✅ Cast label to integer (required for MLlib)\n",
    "spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4218:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "|index|       cleaned_title|        cleaned_text|               label|num_special_chars|num_determinants|num_capital_letters|num_short_sentences|num_long_sentences|       gunning_fog|              smog|               ari|            polarity|title_similarity|       subjectivity|num_syllables|num_words|       rate_adj_adv|words_per_sentence|num_articles|num_verbs|num_sentences|num_adjectives|num_adverbs|\n",
      "+-----+--------------------+--------------------+--------------------+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "|11692|California's Driv...|\"The Pioneer Cabi...| \"\"The Biggest Ba...|               11|               5|                 15|                  0|                 1|16.400000000000002|14.554592549557764|15.279400000000003|0.016666666666666663|             0.0| 0.6833333333333332|           78|       50|                0.1|              25.0|           5|        7|            2|             3|          2|\n",
      "|12081|Italy Brokers Dea...|\"ROME (AFP) The I...|   000 kilometres (3|               17|              13|                 29|                  0|                 2|17.181818181818183|15.579741850924794|15.869999999999997|0.014285714285714282|             0.0|0.17142857142857143|          185|      107| 0.1308411214953271|             26.75|          13|       16|            4|            12|          2|\n",
      "|69891|Think Hillary Cli...|\"Donald J. Trump,...|        1936 or 1964|               28|              20|                 41|                 11|                 3| 10.15855855855856| 10.74609503303851| 7.692612612612617|  0.1457142857142857|             0.0|  0.491547619047619|          363|      208|0.15865384615384615|10.947368421052632|          20|       35|           19|            17|         16|\n",
      "| 8244|Right-Wing Militi...|\"Videos Right-Win...|    2016 Be Sociable|                8|               3|                 14|                  1|                 1| 22.66666666666667|20.267338824336647|19.550967741935487|                 0.0|             0.0|                0.1|           60|       28|0.07142857142857142|              14.0|           3|        2|            2|             1|          1|\n",
      "|27562|US Admits Use of ...|\"Videos US Admits...|    2016 Be Sociable|               13|               5|                 26|                  2|                 1| 13.07450980392157|13.023866798666859| 9.442499999999999|                 0.0|             0.0|                0.0|           80|       46|                0.0|              11.5|           5|        6|            4|             0|          0|\n",
      "+-----+--------------------+--------------------+--------------------+-----------------+----------------+-------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+----------------+-------------------+-------------+---------+-------------------+------------------+------------+---------+-------------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, rand, row_number\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.appName(\"WELFake Features\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "feature_schema = StructType([\n",
    "    StructField(\"num_special_chars\", IntegerType()),\n",
    "    StructField(\"num_determinants\", IntegerType()),\n",
    "    StructField(\"num_capital_letters\", IntegerType()),\n",
    "    StructField(\"num_short_sentences\", IntegerType()),\n",
    "    StructField(\"num_long_sentences\", IntegerType()),\n",
    "    StructField(\"gunning_fog\", DoubleType()),\n",
    "    StructField(\"smog\", DoubleType()),\n",
    "    StructField(\"ari\", DoubleType()),\n",
    "    StructField(\"polarity\", DoubleType()),\n",
    "    StructField(\"title_similarity\", DoubleType()),\n",
    "    StructField(\"subjectivity\", DoubleType()),\n",
    "    StructField(\"num_syllables\", IntegerType()),\n",
    "    StructField(\"num_words\", IntegerType()),\n",
    "    StructField(\"rate_adj_adv\", DoubleType()),\n",
    "    StructField(\"words_per_sentence\", DoubleType()),\n",
    "    StructField(\"num_articles\", IntegerType()),\n",
    "    StructField(\"num_verbs\", IntegerType()),\n",
    "    StructField(\"num_sentences\", IntegerType()),\n",
    "    StructField(\"num_adjectives\", IntegerType()),\n",
    "    StructField(\"num_adverbs\", IntegerType())\n",
    "])\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        pos_tags = pos_tag(words)\n",
    "\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', text))\n",
    "        num_determinants = sum(1 for w in words if w.lower() in ['the', 'a', 'an'])\n",
    "        num_capital_letters = sum(1 for c in text if c.isupper())\n",
    "        num_short_sent = sum(1 for s in sentences if len(s.split()) < 10)\n",
    "        num_long_sent = sum(1 for s in sentences if len(s.split()) > 20)\n",
    "\n",
    "        gunning_fog = textstat.gunning_fog(text)\n",
    "        smog = textstat.smog_index(text)\n",
    "        ari = textstat.automated_readability_index(text)\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "        title_similarity = 0.0\n",
    "\n",
    "        num_syllables = textstat.syllable_count(text)\n",
    "        num_words = len(words)\n",
    "        num_sentences = len([s for s in sentences if s.strip()])\n",
    "        num_adjectives = sum(1 for _, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS'])\n",
    "        num_adverbs = sum(1 for _, tag in pos_tags if tag in ['RB', 'RBR', 'RBS'])\n",
    "        num_verbs = sum(1 for _, tag in pos_tags if tag.startswith('VB'))\n",
    "        num_articles = sum(1 for w in words if w.lower() in ['a', 'an', 'the'])\n",
    "\n",
    "        rate_adj_adv = (num_adjectives + num_adverbs) / num_words if num_words > 0 else 0\n",
    "        words_per_sent = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "        return (\n",
    "            num_special_chars, num_determinants, num_capital_letters, num_short_sent, num_long_sent,\n",
    "            gunning_fog, smog, ari,\n",
    "            polarity, title_similarity, subjectivity,\n",
    "            num_syllables, num_words, rate_adj_adv, words_per_sent,\n",
    "            num_articles, num_verbs, num_sentences, num_adjectives, num_adverbs\n",
    "        )\n",
    "    except:\n",
    "        return (None,) * 20\n",
    "\n",
    "# Register UDF\n",
    "extract_features_udf = udf(extract_features, feature_schema)\n",
    "\n",
    "# Load dataset\n",
    "spark_df = spark.read.csv(\"cleaned_welfake.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# --- Stratified sampling with Window (exact N per label) ---\n",
    "n = 100  # number of rows per class\n",
    "w = Window.partitionBy(\"label\").orderBy(rand(seed=42))\n",
    "df_ranked = spark_df.withColumn(\"row_num\", row_number().over(w))\n",
    "df_sampled = df_ranked.filter(col(\"row_num\") <= n).drop(\"row_num\")\n",
    "\n",
    "# Apply feature extraction\n",
    "df_with_features = df_sampled.withColumn(\"features\", extract_features_udf(\"cleaned_text\"))\n",
    "\n",
    "# Flatten struct\n",
    "for col_name in feature_schema.fieldNames():\n",
    "    df_with_features = df_with_features.withColumn(col_name, df_with_features[\"features\"][col_name])\n",
    "\n",
    "df_with_features = df_with_features.drop(\"features\")\n",
    "\n",
    "df_with_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f391fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4220:=======>                                             (29 + 8) / 200]\r"
     ]
    }
   ],
   "source": [
    "df_with_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce797615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4220:===>                                                 (15 + 8) / 200]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# --------------------------------------\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Stage 1: feature extraction (tokenizer + cv + idf + assemblers)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# --------------------------------------\u001b[39;00m\n\u001b[1;32m     56\u001b[0m base_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39m[tokenizer, cv, idf, vec1, vec2, vec3])\n\u001b[0;32m---> 57\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mbase_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m train_feats \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mtransform(train_df)\n\u001b[1;32m     59\u001b[0m test_feats  \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mtransform(test_df)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/ml/base.py:129\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/ml/pipeline.py:109\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/ml/base.py:129\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/ml/wrapper.py:321\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 321\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/pyspark/ml/wrapper.py:318\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m:return: fitted Java model\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Documents/Projects/fake-news-detection/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4220:====>                                                (16 + 8) / 200]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from functools import reduce\n",
    "\n",
    "# --------------------------------------\n",
    "# Spark session\n",
    "# --------------------------------------\n",
    "spark = SparkSession.builder.appName(\"WELFake-PySpark\").getOrCreate()\n",
    "\n",
    "# --------------------------------------\n",
    "# Define LFS feature groups (same as sklearn version)\n",
    "# --------------------------------------\n",
    "LFS1 = ['num_special_chars','num_determinants','num_capital_letters',\n",
    "        'gunning_fog','polarity','num_syllables']\n",
    "LFS2 = ['num_short_sentences','smog','title_similarity',\n",
    "        'subjectivity','num_words','rate_adj_adv']\n",
    "LFS3 = ['num_long_sentences','ari','num_articles',\n",
    "        'num_verbs','num_sentences','words_per_sentence']\n",
    "\n",
    "# --------------------------------------\n",
    "# Tokenizer + CV + TF-IDF\n",
    "# --------------------------------------\n",
    "tokenizer = RegexTokenizer(inputCol=\"cleaned_text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"cv_features\", vocabSize=5000, minDF=2)\n",
    "idf = IDF(inputCol=\"cv_features\", outputCol=\"tfidf_features\")\n",
    "\n",
    "# Assemble CV+LFS features\n",
    "vec1 = VectorAssembler(inputCols=LFS1 + [\"cv_features\"], outputCol=\"features_lfs1\")\n",
    "vec2 = VectorAssembler(inputCols=LFS2 + [\"cv_features\"], outputCol=\"features_lfs2\")\n",
    "vec3 = VectorAssembler(inputCols=LFS3 + [\"cv_features\"], outputCol=\"features_lfs3\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Train/test split\n",
    "# --------------------------------------\n",
    "# # ✅ Ensure DataFrame is Spark DataFrame (handles Pandas >= 2.0 too)\n",
    "# if \"pandas\" in str(type(df_sampled)):\n",
    "#     try:\n",
    "#         spark_df = spark.createDataFrame(df_sampled)  # direct conversion\n",
    "#     except Exception:\n",
    "#         # fallback for Pandas >= 2.0\n",
    "#         spark_df = spark.createDataFrame([Row(**row) for row in df_sampled.to_dict(orient=\"records\")])\n",
    "# else:\n",
    "#     spark_df = df_sampled\n",
    "\n",
    "# # ✅ Cast label to integer (required for MLlib)\n",
    "# spark_df = spark_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "train_df, test_df = df_with_features.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 1: feature extraction (tokenizer + cv + idf + assemblers)\n",
    "# --------------------------------------\n",
    "base_pipeline = Pipeline(stages=[tokenizer, cv, idf, vec1, vec2, vec3])\n",
    "base_model = base_pipeline.fit(train_df)\n",
    "train_feats = base_model.transform(train_df)\n",
    "test_feats  = base_model.transform(test_df)\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 1: train three SVMs on LFS1/2/3\n",
    "# --------------------------------------\n",
    "svm1 = LinearSVC(featuresCol=\"features_lfs1\", labelCol=\"label\", predictionCol=\"pred1\", rawPredictionCol=\"raw1\")\n",
    "svm2 = LinearSVC(featuresCol=\"features_lfs2\", labelCol=\"label\", predictionCol=\"pred2\", rawPredictionCol=\"raw2\")\n",
    "svm3 = LinearSVC(featuresCol=\"features_lfs3\", labelCol=\"label\", predictionCol=\"pred3\", rawPredictionCol=\"raw3\")\n",
    "\n",
    "svm1_model = svm1.fit(train_feats)\n",
    "svm2_model = svm2.fit(train_feats)\n",
    "svm3_model = svm3.fit(train_feats)\n",
    "\n",
    "# Predictions from each SVM\n",
    "preds1 = svm1_model.transform(test_feats).select(\"index\",\"pred1\")\n",
    "preds2 = svm2_model.transform(test_feats).select(\"index\",\"pred2\")\n",
    "preds3 = svm3_model.transform(test_feats).select(\"index\",\"pred3\")\n",
    "\n",
    "# Join predictions + label\n",
    "preds_all = reduce(\n",
    "    lambda l,r: l.join(r, on=\"index\"),\n",
    "    [test_feats.select(\"index\",\"label\"), preds1, preds2, preds3]\n",
    ")\n",
    "\n",
    "# Majority vote UDF\n",
    "vote_udf = F.udf(lambda p1,p2,p3: int(round((p1+p2+p3)/3.0)), IntegerType())\n",
    "preds_all = preds_all.withColumn(\"stage1_vote\", vote_udf(\"pred1\",\"pred2\",\"pred3\"))\n",
    "\n",
    "# --------------------------------------\n",
    "# Stage 2: CV-only and TF-IDF-only models\n",
    "# --------------------------------------\n",
    "vec_cv = VectorAssembler(inputCols=[\"cv_features\"], outputCol=\"cv_final\")\n",
    "vec_tfidf = VectorAssembler(inputCols=[\"tfidf_features\"], outputCol=\"tfidf_final\")\n",
    "\n",
    "train_feats2 = vec_cv.transform(train_feats)\n",
    "train_feats2 = vec_tfidf.transform(train_feats2)\n",
    "test_feats2  = vec_cv.transform(test_feats)\n",
    "test_feats2  = vec_tfidf.transform(test_feats2)\n",
    "\n",
    "svm_cv = LinearSVC(featuresCol=\"cv_final\", labelCol=\"label\", predictionCol=\"pred_cv\", rawPredictionCol=\"rawCV\")\n",
    "svm_tfidf = LinearSVC(featuresCol=\"tfidf_final\", labelCol=\"label\", predictionCol=\"pred_tfidf\", rawPredictionCol=\"rawTFIDF\")\n",
    "\n",
    "svm_cv_model = svm_cv.fit(train_feats2)\n",
    "svm_tfidf_model = svm_tfidf.fit(train_feats2)\n",
    "\n",
    "preds_cv = svm_cv_model.transform(test_feats2).select(\"index\",\"pred_cv\")\n",
    "preds_tfidf = svm_tfidf_model.transform(test_feats2).select(\"index\",\"pred_tfidf\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Final voting: combine Stage1 vote + CV + TF-IDF\n",
    "# --------------------------------------\n",
    "final_preds = preds_all.join(preds_cv, on=\"index\").join(preds_tfidf, on=\"index\")\n",
    "\n",
    "final_vote_udf = F.udf(lambda p1,p2,p3: int(round((p1+p2+p3)/3.0)), IntegerType())\n",
    "final_preds = final_preds.withColumn(\"final_vote\", final_vote_udf(\"stage1_vote\",\"pred_cv\",\"pred_tfidf\"))\n",
    "\n",
    "# --------------------------------------\n",
    "# Evaluate accuracy\n",
    "# --------------------------------------\n",
    "accuracy = final_preds.filter(F.col(\"final_vote\") == F.col(\"label\")).count() / final_preds.count()\n",
    "print(\"Final Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welfake-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
